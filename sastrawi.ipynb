{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57e2fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menggunakan direktori kerja saat ini sebagai basis: /home/xerces/project/stemming-project\n",
      "Menginisialisasi stemmer Sastrawi...\n",
      "Stemmer siap.\n",
      "Folder output sudah ada: /home/xerces/project/stemming-project/output/sastrawi\n",
      "Folder output sudah ada: /home/xerces/project/stemming-project/output/cleaned\n",
      "\n",
      "Memulai proses cleaning dan stemming dari folder: /home/xerces/project/stemming-project/input/indo\n",
      "  -> Memproses file: Kel3_Peran Bimbingan dan Konseling Dalam Pendidikan Karakter    .txt...\n",
      "  -> Memproses file: Kel6_Benarkah anak-anak butuh mata pelajaran koding dan AI di sekolah.txt...\n",
      "  -> Memproses file: Dampak Tarif Resiprokal Trump terhadap Industri di Indonesia_1.txt...\n",
      "  -> Memproses file: Global South dan Ilusi Netralitas_10.txt...\n",
      "  -> Memproses file: Eksistensi Media Massa Nasional_5.txt...\n",
      "  -> Memproses file: Peran Media Massa dalam Membentuk Opini Publik_5.txt...\n",
      "  -> Memproses file: Kelompok 8_Ini 5 Bahaya Makanan Junk Food yang Perlu Diwaspadai.txt...\n",
      "  -> Memproses file: Kelompok7_Okupasi Senyap Ruang Angkasa.txt...\n",
      "  -> Memproses file: Kel6_Bagaimana mengubah  eco-anxiety kita menjadi aksi untuk Bumi.txt...\n",
      "  -> Memproses file: Kelompok 8_Ketika Jas Putih Menjadi Tameng Menggugat Sistem Pendidikan Dokter Spesialis di Indonesia (1).txt...\n",
      "  -> Memproses file: Kelompok 8_Rupiah di Tengah Perekonomian yang Tertekan.txt...\n",
      "  -> Memproses file: Kel3_Makna Kebersamaan dalam Tradisi Mengibung dan Kembul Bejana.txt...\n",
      "  -> Memproses file: Dugaan Ekspoitasi Mantan Pemain Sirkus, Komisi III DPR Gelar Audiensi Hari ini_2.txt...\n",
      "  -> Memproses file: Kel3_Senarai Catatan di Hari Buku Sedunia dan Tantangan Literasi Indonesia.txt...\n",
      "  -> Memproses file: Kelompok9_Rupiah di Tengah Perekonomian yang Tertekan.txt...\n",
      "  -> Memproses file: Gonjang-ganjing Isu Evakuasi Warga Gaza ke Indonesia_2.txt...\n",
      "  -> Memproses file: Korupsi yang Menjegal Daerah_2.txt...\n",
      "  -> Memproses file: Untuk Bantu Pahami Matematika, Anak Perlu Metode Belajar Interaktif_5.txt...\n",
      "  -> Memproses file: Kel6_Kecanduan media sosial bikin anak muda rentan kena gangguan makan.txt...\n",
      "  -> Memproses file: Kelompok7_Teknologi Dirgantara Untuk Operasi Bantuan Kemanusiaan.txt...\n",
      "  -> Memproses file: Kelompok9_China Ancam Negara-negara yang Negosiasi Perang Tarif Trump.txt...\n",
      "  -> Memproses file: 4 Calon Kuat Penerus Paus Fransiskus, Ada dari Tetangga RI_10.txt...\n",
      "  -> Memproses file: Melanjutkan Cita-cita Politik Kartini_4.txt...\n",
      "  -> Memproses file: Kelompok7_Pendidikan Dasar dan Menengah yang bermutu untuk seluruh rakyat.txt...\n",
      "  -> Memproses file: Merawat Kartini di Kebun Nirkertas_9.txt...\n",
      "  -> Memproses file: Ragam Keluhan Mitra MBG Menalangi Biaya hingga Jual Barang Pribadi_Kel 1.txt...\n",
      "  -> Memproses file: AS Soroti QRIS & GPN dalam Negosiasi Dagang, Ini Alasannya_1.txt...\n",
      "  -> Memproses file: TKDN dan Negosiasi Dagang RI-AS_10.txt...\n",
      "  -> Memproses file: Robot Ikut Lomba Lari_4.txt...\n",
      "  -> Memproses file: Dilema Persalinan Caesar di Era JKN Antara Hak Ibu dan Efisiensi Anggaran_4.txt...\n",
      "\n",
      "Proses cleaning dan stemming selesai.\n",
      "Jumlah file .txt yang diproses: 30\n",
      "Hasil stemming disimpan di: /home/xerces/project/stemming-project/output/sastrawi\n",
      "Hasil cleaning (tanpa stemming) disimpan di: /home/xerces/project/stemming-project/output/cleaned\n",
      "Total waktu eksekusi: 60.16 detik\n",
      "\n",
      "--- Evaluasi Reduksi Kosakata ---\n",
      "Total kata (tokens) setelah cleaning: 22565\n",
      "Total kata (tokens) setelah stemming: 22596\n",
      "Jumlah kata unik (types) setelah cleaning: 4503\n",
      "Jumlah kata unik (types) setelah stemming: 3115\n",
      "Persentase reduksi kosakata unik: 30.82%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import time\n",
    "from collections import Counter # Counter tidak digunakan secara aktif, tapi bisa berguna nanti\n",
    "\n",
    "# --- Konfigurasi ---\n",
    "NAMA_FOLDER_INPUT = 'input'\n",
    "# Folder untuk hasil akhir yang berisi perbandingan\n",
    "NAMA_FOLDER_OUTPUT_COMPARISON_RELATIF = 'output/sastrawi_comparison'\n",
    "# Folder untuk hasil cleaning saja (opsional, bisa dihapus jika tidak perlu)\n",
    "NAMA_FOLDER_OUTPUT_CLEANED_RELATIF = 'output/cleaned'\n",
    "# --- Akhir Konfigurasi ---\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "print(f\"Menggunakan direktori kerja saat ini sebagai basis: {base_dir}\")\n",
    "input_folder_path = os.path.join(base_dir, NAMA_FOLDER_INPUT)\n",
    "output_folder_comparison_path = os.path.join(base_dir, NAMA_FOLDER_OUTPUT_COMPARISON_RELATIF)\n",
    "output_folder_cleaned_path = os.path.join(base_dir, NAMA_FOLDER_OUTPUT_CLEANED_RELATIF)\n",
    "\n",
    "# --- Fungsi untuk Membersihkan Teks (Mempertahankan Newline) ---\n",
    "def bersihkan_teks_preserve_lines(teks):\n",
    "    lines = teks.splitlines()\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        tanda_baca_escaped = re.escape(string.punctuation)\n",
    "        line = re.sub(r'[' + tanda_baca_escaped + ']', '', line)\n",
    "        line = re.sub(r'[ \\t]+', ' ', line)\n",
    "        line = line.strip()\n",
    "        # Menjaga struktur paragraf, bahkan baris kosong jika hanya berisi whitespace setelah clean\n",
    "        # Jika ingin menghapus baris yang jadi kosong total: if line: cleaned_lines.append(line)\n",
    "        cleaned_lines.append(line) # Mempertahankan baris (meskipun kosong setelah clean)\n",
    "    # Gabung kembali, pastikan ada newline di akhir jika teks asli punya\n",
    "    hasil = '\\n'.join(cleaned_lines)\n",
    "    # Jika teks asli diakhiri newline, tambahkan kembali\n",
    "    if teks.endswith('\\n') and not hasil.endswith('\\n'):\n",
    "         hasil += '\\n'\n",
    "    return hasil\n",
    "# --- Akhir Fungsi Cleaning ---\n",
    "\n",
    "# 1. Inisialisasi Stemmer Sastrawi\n",
    "print(\"Menginisialisasi stemmer Sastrawi...\")\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "print(\"Stemmer siap.\")\n",
    "\n",
    "# 2. Buat folder output\n",
    "# Folder untuk perbandingan WAJIB dibuat\n",
    "if not os.path.exists(output_folder_comparison_path):\n",
    "    os.makedirs(output_folder_comparison_path)\n",
    "    print(f\"Folder output perbandingan dibuat: {output_folder_comparison_path}\")\n",
    "else:\n",
    "    print(f\"Folder output perbandingan sudah ada: {output_folder_comparison_path}\")\n",
    "\n",
    "# Folder untuk cleaned saja (OPSIONAL) - Jika tidak mau, komentari bagian ini\n",
    "if not os.path.exists(output_folder_cleaned_path):\n",
    "    os.makedirs(output_folder_cleaned_path)\n",
    "    print(f\"Folder output cleaned-only dibuat: {output_folder_cleaned_path}\")\n",
    "else:\n",
    "    print(f\"Folder output cleaned-only sudah ada: {output_folder_cleaned_path}\")\n",
    "\n",
    "\n",
    "# Variabel Evaluasi TOTAL (untuk console)\n",
    "unique_words_cleaned_total = set()\n",
    "unique_words_stemmed_total = set()\n",
    "total_words_cleaned_all_files = 0\n",
    "total_words_stemmed_all_files = 0\n",
    "\n",
    "# 3. Proses setiap file\n",
    "print(f\"\\nMemulai proses cleaning dan stemming dari folder: {input_folder_path}\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    if not os.path.isdir(input_folder_path):\n",
    "        raise FileNotFoundError(f\"Folder input '{input_folder_path}' tidak ditemukan.\")\n",
    "\n",
    "    list_file = os.listdir(input_folder_path)\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "\n",
    "    if not list_file:\n",
    "        print(\"Folder input kosong.\")\n",
    "\n",
    "    for filename in list_file:\n",
    "        input_file_path = os.path.join(input_folder_path, filename)\n",
    "\n",
    "        if os.path.isfile(input_file_path) and filename.lower().endswith('.txt'):\n",
    "            # Path untuk file output yang berisi perbandingan\n",
    "            output_file_comparison_path = os.path.join(output_folder_comparison_path, filename)\n",
    "            # Path untuk file output cleaned-only (opsional)\n",
    "            output_file_cleaned_path = os.path.join(output_folder_cleaned_path, filename)\n",
    "\n",
    "            print(f\"  -> Memproses file: {filename}...\")\n",
    "\n",
    "            try:\n",
    "                with open(input_file_path, 'r', encoding='utf-8', errors='ignore') as f_in:\n",
    "                    original_text = f_in.read()\n",
    "\n",
    "                # Lakukan Cleaning Teks\n",
    "                cleaned_text = bersihkan_teks_preserve_lines(original_text)\n",
    "\n",
    "                # --- Simpan Teks yang Hanya Dibersihkan (OPSIONAL) ---\n",
    "                # Jika tidak butuh file cleaned terpisah, komentari/hapus blok ini\n",
    "                with open(output_file_cleaned_path, 'w', encoding='utf-8') as f_clean:\n",
    "                    f_clean.write(cleaned_text)\n",
    "                # --- Akhir blok opsional ---\n",
    "\n",
    "                # Lakukan stemming pada teks yang sudah dibersihkan\n",
    "                stemmed_text = stemmer.stem(cleaned_text)\n",
    "\n",
    "                # --- Hitung Statistik UNTUK FILE INI ---\n",
    "                cleaned_words_list = cleaned_text.split()\n",
    "                stemmed_words_list = stemmed_text.split()\n",
    "\n",
    "                count_cleaned_words = len(cleaned_words_list)\n",
    "                count_unique_cleaned = len(set(cleaned_words_list))\n",
    "                count_stemmed_words = len(stemmed_words_list)\n",
    "                count_unique_stemmed = len(set(stemmed_words_list))\n",
    "                # --- Akhir Hitung Statistik File Ini ---\n",
    "\n",
    "\n",
    "                # --- Buat Konten untuk File Output Perbandingan ---\n",
    "                file_header = f\"\"\"=============================================\n",
    "FILE: {filename} - STATISTIK\n",
    "=============================================\n",
    "Jumlah Kata (Setelah Cleaning): {count_cleaned_words}\n",
    "Jumlah Kata Unik (Setelah Cleaning): {count_unique_cleaned}\n",
    "Jumlah Kata (Setelah Stemming): {count_stemmed_words}\n",
    "Jumlah Kata Unik (Setelah Stemming): {count_unique_stemmed}\n",
    "=============================================\n",
    "\n",
    "\"\"\"\n",
    "                separator_cleaned = \"\\n--- TEKS SETELAH CLEANING (SEBELUM STEMMING) ---\\n\"\n",
    "                separator_stemmed = \"\\n\\n--- TEKS SETELAH STEMMING ---\\n\" # Tambah newline ekstra\n",
    "\n",
    "                final_comparison_content = (\n",
    "                    file_header +\n",
    "                    separator_cleaned +\n",
    "                    cleaned_text +\n",
    "                    separator_stemmed +\n",
    "                    stemmed_text\n",
    "                )\n",
    "                # --- Akhir Pembuatan Konten ---\n",
    "\n",
    "\n",
    "                # Tulis hasil perbandingan ke file output\n",
    "                with open(output_file_comparison_path, 'w', encoding='utf-8') as f_comparison:\n",
    "                    f_comparison.write(final_comparison_content)\n",
    "\n",
    "\n",
    "                # Update Statistik TOTAL (untuk console)\n",
    "                unique_words_cleaned_total.update(set(cleaned_words_list))\n",
    "                unique_words_stemmed_total.update(set(stemmed_words_list))\n",
    "                total_words_cleaned_all_files += count_cleaned_words\n",
    "                total_words_stemmed_all_files += count_stemmed_words\n",
    "\n",
    "                processed_files += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"     ERROR saat memproses file {filename}: {e}\")\n",
    "        else:\n",
    "            if os.path.isfile(input_file_path):\n",
    "                 print(f\"  -> Melewati file non-txt: {filename}\")\n",
    "            else:\n",
    "                 print(f\"  -> Melewati item yang bukan file: {filename}\")\n",
    "            skipped_files += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    print(f\"\\nProses cleaning dan stemming selesai.\")\n",
    "    print(f\"Jumlah file .txt yang diproses: {processed_files}\")\n",
    "    if skipped_files > 0:\n",
    "        print(f\"Jumlah item non-txt/subfolder yang dilewati: {skipped_files}\")\n",
    "    print(f\"Hasil perbandingan disimpan di: {output_folder_comparison_path}\") # Path output baru\n",
    "    # Pesan untuk folder cleaned-only (opsional)\n",
    "    if os.path.exists(output_folder_cleaned_path):\n",
    "         print(f\"Hasil cleaning saja disimpan di: {output_folder_cleaned_path}\")\n",
    "    print(f\"Total waktu eksekusi: {total_time:.2f} detik\")\n",
    "\n",
    "    # Cetak Hasil Evaluasi Reduksi Kosakata TOTAL (dari semua file)\n",
    "    print(\"\\n--- Evaluasi Reduksi Kosakata TOTAL (Semua File) ---\")\n",
    "    count_unique_cleaned_total = len(unique_words_cleaned_total)\n",
    "    count_unique_stemmed_total = len(unique_words_stemmed_total)\n",
    "    print(f\"Total kata (tokens) setelah cleaning (semua file): {total_words_cleaned_all_files}\")\n",
    "    print(f\"Total kata (tokens) setelah stemming (semua file): {total_words_stemmed_all_files}\")\n",
    "    print(f\"Jumlah kata unik (types) setelah cleaning (semua file): {count_unique_cleaned_total}\")\n",
    "    print(f\"Jumlah kata unik (types) setelah stemming (semua file): {count_unique_stemmed_total}\")\n",
    "\n",
    "    if count_unique_cleaned_total > 0:\n",
    "        reduction_percentage_total = ((count_unique_cleaned_total - count_unique_stemmed_total) / count_unique_cleaned_total) * 100\n",
    "        print(f\"Persentase reduksi kosakata unik TOTAL: {reduction_percentage_total:.2f}%\")\n",
    "    else:\n",
    "        print(\"Tidak ada kata unik untuk menghitung reduksi total.\")\n",
    "\n",
    "except FileNotFoundError as fnf_error:\n",
    "    print(f\"ERROR: {fnf_error}\")\n",
    "    print(\"Pastikan folder input ada.\")\n",
    "except Exception as e:\n",
    "    print(f\"Terjadi kesalahan umum: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
