{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57e2fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menggunakan direktori kerja saat ini sebagai basis: /home/xerces/project/stemming-project\n",
      "Menginisialisasi stemmer Sastrawi...\n",
      "Stemmer siap.\n",
      "Folder output perbandingan dibuat: /home/xerces/project/stemming-project/output/sastrawi_comparison\n",
      "Folder output cleaned-only sudah ada: /home/xerces/project/stemming-project/output/cleaned\n",
      "\n",
      "Memulai proses cleaning dan stemming dari folder: /home/xerces/project/stemming-project/input/indo\n",
      "  -> Memproses file: Kel3_Peran Bimbingan dan Konseling Dalam Pendidikan Karakter    .txt...\n",
      "  -> Memproses file: Kel6_Benarkah anak-anak butuh mata pelajaran koding dan AI di sekolah.txt...\n",
      "  -> Memproses file: Dampak Tarif Resiprokal Trump terhadap Industri di Indonesia_1.txt...\n",
      "  -> Memproses file: Global South dan Ilusi Netralitas_10.txt...\n",
      "  -> Memproses file: Eksistensi Media Massa Nasional_5.txt...\n",
      "  -> Memproses file: Peran Media Massa dalam Membentuk Opini Publik_5.txt...\n",
      "  -> Memproses file: Kelompok 8_Ini 5 Bahaya Makanan Junk Food yang Perlu Diwaspadai.txt...\n",
      "  -> Memproses file: Kelompok7_Okupasi Senyap Ruang Angkasa.txt...\n",
      "  -> Memproses file: Kel6_Bagaimana mengubah  eco-anxiety kita menjadi aksi untuk Bumi.txt...\n",
      "  -> Memproses file: Kelompok 8_Ketika Jas Putih Menjadi Tameng Menggugat Sistem Pendidikan Dokter Spesialis di Indonesia (1).txt...\n",
      "  -> Memproses file: Kelompok 8_Rupiah di Tengah Perekonomian yang Tertekan.txt...\n",
      "  -> Memproses file: Kel3_Makna Kebersamaan dalam Tradisi Mengibung dan Kembul Bejana.txt...\n",
      "  -> Memproses file: Dugaan Ekspoitasi Mantan Pemain Sirkus, Komisi III DPR Gelar Audiensi Hari ini_2.txt...\n",
      "  -> Memproses file: Kel3_Senarai Catatan di Hari Buku Sedunia dan Tantangan Literasi Indonesia.txt...\n",
      "  -> Memproses file: Kelompok9_Rupiah di Tengah Perekonomian yang Tertekan.txt...\n",
      "  -> Memproses file: Gonjang-ganjing Isu Evakuasi Warga Gaza ke Indonesia_2.txt...\n",
      "  -> Memproses file: Korupsi yang Menjegal Daerah_2.txt...\n",
      "  -> Memproses file: Untuk Bantu Pahami Matematika, Anak Perlu Metode Belajar Interaktif_5.txt...\n",
      "  -> Memproses file: Kel6_Kecanduan media sosial bikin anak muda rentan kena gangguan makan.txt...\n",
      "  -> Memproses file: Kelompok7_Teknologi Dirgantara Untuk Operasi Bantuan Kemanusiaan.txt...\n",
      "  -> Memproses file: Kelompok9_China Ancam Negara-negara yang Negosiasi Perang Tarif Trump.txt...\n",
      "  -> Memproses file: 4 Calon Kuat Penerus Paus Fransiskus, Ada dari Tetangga RI_10.txt...\n",
      "  -> Memproses file: Melanjutkan Cita-cita Politik Kartini_4.txt...\n",
      "  -> Memproses file: Kelompok7_Pendidikan Dasar dan Menengah yang bermutu untuk seluruh rakyat.txt...\n",
      "  -> Memproses file: Merawat Kartini di Kebun Nirkertas_9.txt...\n",
      "  -> Memproses file: Ragam Keluhan Mitra MBG Menalangi Biaya hingga Jual Barang Pribadi_Kel 1.txt...\n",
      "  -> Memproses file: AS Soroti QRIS & GPN dalam Negosiasi Dagang, Ini Alasannya_1.txt...\n",
      "  -> Memproses file: TKDN dan Negosiasi Dagang RI-AS_10.txt...\n",
      "  -> Memproses file: Robot Ikut Lomba Lari_4.txt...\n",
      "  -> Memproses file: Dilema Persalinan Caesar di Era JKN Antara Hak Ibu dan Efisiensi Anggaran_4.txt...\n",
      "\n",
      "Proses cleaning dan stemming selesai.\n",
      "Jumlah file .txt yang diproses: 30\n",
      "Hasil perbandingan disimpan di: /home/xerces/project/stemming-project/output/sastrawi_comparison\n",
      "Hasil cleaning saja disimpan di: /home/xerces/project/stemming-project/output/cleaned\n",
      "Total waktu eksekusi: 59.48 detik\n",
      "\n",
      "--- Evaluasi Reduksi Kosakata TOTAL (Semua File) ---\n",
      "Total kata (tokens) setelah cleaning (semua file): 22565\n",
      "Total kata (tokens) setelah stemming (semua file): 22596\n",
      "Jumlah kata unik (types) setelah cleaning (semua file): 4503\n",
      "Jumlah kata unik (types) setelah stemming (semua file): 3115\n",
      "Persentase reduksi kosakata unik TOTAL: 30.82%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9147df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import time\n",
    "\n",
    "# --- Konfigurasi ---\n",
    "NAMA_FOLDER_INPUT = 'input'\n",
    "# Folder untuk hasil akhir yang berisi perbandingan\n",
    "NAMA_FOLDER_OUTPUT_COMPARISON_RELATIF = 'output/sastrawi_comparison'\n",
    "# Folder untuk hasil cleaning saja (opsional, bisa dihapus jika tidak perlu)\n",
    "# Jika tidak mau folder ini, hapus atau komentari baris di bawah ini\n",
    "NAMA_FOLDER_OUTPUT_CLEANED_RELATIF = 'output/cleaned'\n",
    "# --- Akhir Konfigurasi ---\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "print(f\"Menggunakan direktori kerja saat ini sebagai basis: {base_dir}\")\n",
    "input_folder_path = os.path.join(base_dir, NAMA_FOLDER_INPUT)\n",
    "output_folder_comparison_path = os.path.join(base_dir, NAMA_FOLDER_OUTPUT_COMPARISON_RELATIF)\n",
    "# Hanya definisikan jika folder cleaned digunakan\n",
    "if 'NAMA_FOLDER_OUTPUT_CLEANED_RELATIF' in locals() and NAMA_FOLDER_OUTPUT_CLEANED_RELATIF:\n",
    "    output_folder_cleaned_path = os.path.join(base_dir, NAMA_FOLDER_OUTPUT_CLEANED_RELATIF)\n",
    "else:\n",
    "    # Jika tidak didefinisikan, set ke None agar pengecekan nanti tidak error\n",
    "    output_folder_cleaned_path = None\n",
    "\n",
    "\n",
    "# --- Fungsi untuk Membersihkan Teks (Mempertahankan Newline - Revisi) ---\n",
    "def bersihkan_teks_preserve_lines(teks):\n",
    "    \"\"\"Membersihkan teks per baris sambil mempertahankan struktur newline.\"\"\"\n",
    "    lines = teks.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    tanda_baca_escaped = re.escape(string.punctuation)\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        line = re.sub(r'[' + tanda_baca_escaped + ']', '', line)\n",
    "        line = re.sub(r'[ \\t]+', ' ', line)\n",
    "        line = line.strip()\n",
    "        cleaned_lines.append(line)\n",
    "    return '\\n'.join(cleaned_lines)\n",
    "# --- Akhir Fungsi Cleaning ---\n",
    "\n",
    "# 1. Inisialisasi Stemmer Sastrawi\n",
    "print(\"Menginisialisasi stemmer Sastrawi...\")\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "print(\"Stemmer siap.\")\n",
    "\n",
    "# 2. Buat folder output\n",
    "if not os.path.exists(output_folder_comparison_path):\n",
    "    os.makedirs(output_folder_comparison_path)\n",
    "    print(f\"Folder output perbandingan dibuat: {output_folder_comparison_path}\")\n",
    "else:\n",
    "    print(f\"Folder output perbandingan sudah ada: {output_folder_comparison_path}\")\n",
    "\n",
    "# Buat folder cleaned jika variabelnya ada dan valid\n",
    "if output_folder_cleaned_path:\n",
    "    if not os.path.exists(output_folder_cleaned_path):\n",
    "        os.makedirs(output_folder_cleaned_path)\n",
    "        print(f\"Folder output cleaned-only dibuat: {output_folder_cleaned_path}\")\n",
    "    else:\n",
    "        print(f\"Folder output cleaned-only sudah ada: {output_folder_cleaned_path}\")\n",
    "\n",
    "# Variabel Evaluasi TOTAL (untuk console)\n",
    "unique_words_original_total = set()\n",
    "unique_words_cleaned_total = set()\n",
    "unique_words_stemmed_total = set()\n",
    "total_words_original_all_files = 0\n",
    "total_words_cleaned_all_files = 0\n",
    "total_words_stemmed_all_files = 0\n",
    "\n",
    "# 3. Proses setiap file\n",
    "print(f\"\\nMemulai proses cleaning dan stemming dari folder: {input_folder_path}\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    if not os.path.isdir(input_folder_path):\n",
    "        raise FileNotFoundError(f\"Folder input '{input_folder_path}' tidak ditemukan.\")\n",
    "\n",
    "    list_file = os.listdir(input_folder_path)\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "\n",
    "    if not list_file:\n",
    "        print(\"Folder input kosong.\")\n",
    "\n",
    "    for filename in list_file:\n",
    "        input_file_path = os.path.join(input_folder_path, filename)\n",
    "\n",
    "        if os.path.isfile(input_file_path) and filename.lower().endswith('.txt'):\n",
    "            output_file_comparison_path = os.path.join(output_folder_comparison_path, filename)\n",
    "            # Path opsional untuk file cleaned\n",
    "            current_output_cleaned_path = None\n",
    "            if output_folder_cleaned_path: # Cek jika path utama valid\n",
    "                current_output_cleaned_path = os.path.join(output_folder_cleaned_path, filename)\n",
    "\n",
    "            print(f\"  -> Memproses file: {filename}...\")\n",
    "\n",
    "            try:\n",
    "                with open(input_file_path, 'r', encoding='utf-8', errors='ignore') as f_in:\n",
    "                    original_text = f_in.read()\n",
    "\n",
    "                # *** HITUNG STATISTIK ORIGINAL ***\n",
    "                original_words_list = original_text.split() # Split sederhana utk hitung kata\n",
    "                count_original_words = len(original_words_list)\n",
    "                count_unique_original = len(set(original_words_list))\n",
    "                # *******************************\n",
    "\n",
    "                # Lakukan Cleaning Teks (dengan fungsi yg diperbaiki)\n",
    "                cleaned_text = bersihkan_teks_preserve_lines(original_text)\n",
    "\n",
    "                # Simpan Teks yang Hanya Dibersihkan (OPSIONAL)\n",
    "                if current_output_cleaned_path: # Cek jika path spesifik file ini valid\n",
    "                    with open(current_output_cleaned_path, 'w', encoding='utf-8') as f_clean:\n",
    "                        f_clean.write(cleaned_text)\n",
    "\n",
    "                # Lakukan stemming\n",
    "                stemmed_text = stemmer.stem(cleaned_text)\n",
    "\n",
    "                # Hitung Statistik Cleaned & Stemmed untuk file ini\n",
    "                # Split sederhana sudah cukup karena cleaning sudah menangani spasi\n",
    "                cleaned_words_list = cleaned_text.split()\n",
    "                stemmed_words_list = stemmed_text.split()\n",
    "\n",
    "                count_cleaned_words = len(cleaned_words_list)\n",
    "                count_unique_cleaned = len(set(w for w in cleaned_words_list if w)) # Hitung unik, abaikan string kosong hasil split baris kosong\n",
    "                count_stemmed_words = len(stemmed_words_list)\n",
    "                count_unique_stemmed = len(set(w for w in stemmed_words_list if w)) # Hitung unik, abaikan string kosong\n",
    "\n",
    "                # *** Buat Konten Header dengan Statistik Lengkap (TERMASUK ORIGINAL) *** <--- PERBAIKAN DI SINI\n",
    "                file_header = f\"\"\"=============================================\n",
    "FILE: {filename} - STATISTIK\n",
    "=============================================\n",
    "Jumlah Kata (Original): {count_original_words}\n",
    "Jumlah Kata Unik (Original): {count_unique_original}\n",
    "---------------------------------------------\n",
    "Jumlah Kata (Setelah Cleaning): {count_cleaned_words}\n",
    "Jumlah Kata Unik (Setelah Cleaning): {count_unique_cleaned}\n",
    "---------------------------------------------\n",
    "Jumlah Kata (Setelah Stemming): {count_stemmed_words}\n",
    "Jumlah Kata Unik (Setelah Stemming): {count_unique_stemmed}\n",
    "=============================================\n",
    "\n",
    "\"\"\"\n",
    "                # --- Akhir Perbaikan Header ---\n",
    "\n",
    "                separator_cleaned = \"\\n--- TEKS SETELAH CLEANING (SEBELUM STEMMING) ---\\n\"\n",
    "                separator_stemmed = \"\\n\\n--- TEKS SETELAH STEMMING ---\\n\"\n",
    "\n",
    "                final_comparison_content = (\n",
    "                    file_header +\n",
    "                    separator_cleaned +\n",
    "                    cleaned_text +\n",
    "                    separator_stemmed +\n",
    "                    stemmed_text\n",
    "                )\n",
    "\n",
    "                # Tulis hasil perbandingan\n",
    "                with open(output_file_comparison_path, 'w', encoding='utf-8') as f_comparison:\n",
    "                    f_comparison.write(final_comparison_content)\n",
    "\n",
    "                # Update Statistik TOTAL (untuk console)\n",
    "                total_words_original_all_files += count_original_words\n",
    "                unique_words_original_total.update(w for w in original_words_list if w) # Update set unik original\n",
    "                total_words_cleaned_all_files += count_cleaned_words\n",
    "                unique_words_cleaned_total.update(w for w in cleaned_words_list if w) # Update set unik cleaned\n",
    "                total_words_stemmed_all_files += count_stemmed_words\n",
    "                unique_words_stemmed_total.update(w for w in stemmed_words_list if w) # Update set unik stemmed\n",
    "\n",
    "                processed_files += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"     ERROR saat memproses file {filename}: {e}\")\n",
    "        else:\n",
    "            # Log skip file\n",
    "            if os.path.isfile(input_file_path):\n",
    "                 print(f\"  -> Melewati file non-txt: {filename}\")\n",
    "            elif os.path.exists(input_file_path):\n",
    "                 print(f\"  -> Melewati item yang bukan file (misal: folder): {filename}\")\n",
    "            else: # Handle jika path input tidak ada\n",
    "                 print(f\"  -> Path tidak valid atau tidak ditemukan: {filename}\")\n",
    "            skipped_files += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    print(f\"\\nProses cleaning dan stemming selesai.\")\n",
    "    print(f\"Jumlah file .txt yang diproses: {processed_files}\")\n",
    "    if skipped_files > 0:\n",
    "        print(f\"Jumlah item non-txt/subfolder yang dilewati: {skipped_files}\")\n",
    "    print(f\"Hasil perbandingan disimpan di: {output_folder_comparison_path}\")\n",
    "    if output_folder_cleaned_path and os.path.exists(output_folder_cleaned_path):\n",
    "         print(f\"Hasil cleaning saja disimpan di: {output_folder_cleaned_path}\")\n",
    "    print(f\"Total waktu eksekusi: {total_time:.2f} detik\")\n",
    "\n",
    "    # --- Cetak Hasil Evaluasi Statistik TOTAL (Semua File) ---\n",
    "    print(\"\\n--- Evaluasi Statistik TOTAL (Semua File) ---\")\n",
    "    count_unique_original_total = len(unique_words_original_total)\n",
    "    count_unique_cleaned_total = len(unique_words_cleaned_total)\n",
    "    count_unique_stemmed_total = len(unique_words_stemmed_total)\n",
    "\n",
    "    print(f\"Total kata (tokens) original (semua file): {total_words_original_all_files}\")\n",
    "    print(f\"Jumlah kata unik (types) original (semua file): {count_unique_original_total}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total kata (tokens) setelah cleaning (semua file): {total_words_cleaned_all_files}\")\n",
    "    print(f\"Jumlah kata unik (types) setelah cleaning (semua file): {count_unique_cleaned_total}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total kata (tokens) setelah stemming (semua file): {total_words_stemmed_all_files}\")\n",
    "    print(f\"Jumlah kata unik (types) setelah stemming (semua file): {count_unique_stemmed_total}\")\n",
    "\n",
    "    # --- Perhitungan Persentase Reduksi ---\n",
    "    print(\"-\" * 30)\n",
    "    if count_unique_original_total > 0:\n",
    "        reduction_from_original = ((count_unique_original_total - count_unique_stemmed_total) / count_unique_original_total) * 100\n",
    "        print(f\"Persentase reduksi kosakata unik (Original -> Stemmed): {reduction_from_original:.2f}%\")\n",
    "    else:\n",
    "        print(\"Tidak dapat menghitung reduksi dari Original (kosakata original 0).\")\n",
    "\n",
    "    if count_unique_cleaned_total > 0:\n",
    "        reduction_from_cleaned = ((count_unique_cleaned_total - count_unique_stemmed_total) / count_unique_cleaned_total) * 100\n",
    "        print(f\"Persentase reduksi kosakata unik (Cleaned -> Stemmed): {reduction_from_cleaned:.2f}%\")\n",
    "    else:\n",
    "        print(\"Tidak dapat menghitung reduksi dari Cleaned (kosakata cleaned 0).\")\n",
    "    # --- Akhir Persentase Reduksi ---\n",
    "\n",
    "except FileNotFoundError as fnf_error:\n",
    "    print(f\"ERROR: {fnf_error}\")\n",
    "    print(\"Pastikan folder input ada.\")\n",
    "except Exception as e:\n",
    "    print(f\"Terjadi kesalahan umum: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
