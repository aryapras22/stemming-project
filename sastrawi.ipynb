{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9147df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menggunakan direktori kerja saat ini sebagai basis: /home/xerces/project/stemming-project\n",
      "Menginisialisasi stemmer Sastrawi...\n",
      "Stemmer siap.\n",
      "Folder output perbandingan sudah ada: /home/xerces/project/stemming-project/output/sastrawi_comparison_stats\n",
      "Folder output cleaned-only sudah ada: /home/xerces/project/stemming-project/output/cleaned_stats\n",
      "\n",
      "Memulai proses cleaning dan stemming dari folder: /home/xerces/project/stemming-project/input/indo\n",
      "  -> Memproses file: Kel3_Peran Bimbingan dan Konseling Dalam Pendidikan Karakter    .txt...\n",
      "  -> Memproses file: Kel6_Benarkah anak-anak butuh mata pelajaran koding dan AI di sekolah.txt...\n",
      "     WARN: Jumlah kata cleaned (852) != stemmed (857) untuk file Kel6_Benarkah anak-anak butuh mata pelajaran koding dan AI di sekolah.txt. Proxy Stem Collision tidak dihitung.\n",
      "  -> Memproses file: Dampak Tarif Resiprokal Trump terhadap Industri di Indonesia_1.txt...\n",
      "  -> Memproses file: Global South dan Ilusi Netralitas_10.txt...\n",
      "     WARN: Jumlah kata cleaned (1004) != stemmed (1006) untuk file Global South dan Ilusi Netralitas_10.txt. Proxy Stem Collision tidak dihitung.\n",
      "  -> Memproses file: Eksistensi Media Massa Nasional_5.txt...\n",
      "  -> Memproses file: Peran Media Massa dalam Membentuk Opini Publik_5.txt...\n",
      "  -> Memproses file: Kelompok 8_Ini 5 Bahaya Makanan Junk Food yang Perlu Diwaspadai.txt...\n",
      "     WARN: Jumlah kata cleaned (698) != stemmed (697) untuk file Kelompok 8_Ini 5 Bahaya Makanan Junk Food yang Perlu Diwaspadai.txt. Proxy Stem Collision tidak dihitung.\n",
      "  -> Memproses file: Kelompok7_Okupasi Senyap Ruang Angkasa.txt...\n",
      "     WARN: Jumlah kata cleaned (1052) != stemmed (1057) untuk file Kelompok7_Okupasi Senyap Ruang Angkasa.txt. Proxy Stem Collision tidak dihitung.\n",
      "  -> Memproses file: Kel6_Bagaimana mengubah  eco-anxiety kita menjadi aksi untuk Bumi.txt...\n",
      "  -> Memproses file: Kelompok 8_Ketika Jas Putih Menjadi Tameng Menggugat Sistem Pendidikan Dokter Spesialis di Indonesia (1).txt...\n",
      "  -> Memproses file: Kelompok 8_Rupiah di Tengah Perekonomian yang Tertekan.txt...\n",
      "     WARN: Jumlah kata cleaned (791) != stemmed (796) untuk file Kelompok 8_Rupiah di Tengah Perekonomian yang Tertekan.txt. Proxy Stem Collision tidak dihitung.\n",
      "  -> Memproses file: Kel3_Makna Kebersamaan dalam Tradisi Mengibung dan Kembul Bejana.txt...\n",
      "  -> Memproses file: Dugaan Ekspoitasi Mantan Pemain Sirkus, Komisi III DPR Gelar Audiensi Hari ini_2.txt...\n",
      "  -> Memproses file: Kel3_Senarai Catatan di Hari Buku Sedunia dan Tantangan Literasi Indonesia.txt...\n",
      "  -> Memproses file: Kelompok9_Rupiah di Tengah Perekonomian yang Tertekan.txt...\n",
      "     WARN: Jumlah kata cleaned (784) != stemmed (789) untuk file Kelompok9_Rupiah di Tengah Perekonomian yang Tertekan.txt. Proxy Stem Collision tidak dihitung.\n",
      "  -> Memproses file: Gonjang-ganjing Isu Evakuasi Warga Gaza ke Indonesia_2.txt...\n",
      "  -> Memproses file: Korupsi yang Menjegal Daerah_2.txt...\n",
      "  -> Memproses file: Untuk Bantu Pahami Matematika, Anak Perlu Metode Belajar Interaktif_5.txt...\n",
      "  -> Memproses file: Kel6_Kecanduan media sosial bikin anak muda rentan kena gangguan makan.txt...\n",
      "     WARN: Jumlah kata cleaned (702) != stemmed (703) untuk file Kel6_Kecanduan media sosial bikin anak muda rentan kena gangguan makan.txt. Proxy Stem Collision tidak dihitung.\n",
      "  -> Memproses file: Kelompok7_Teknologi Dirgantara Untuk Operasi Bantuan Kemanusiaan.txt...\n",
      "  -> Memproses file: Kelompok9_China Ancam Negara-negara yang Negosiasi Perang Tarif Trump.txt...\n",
      "  -> Memproses file: 4 Calon Kuat Penerus Paus Fransiskus, Ada dari Tetangga RI_10.txt...\n",
      "  -> Memproses file: Melanjutkan Cita-cita Politik Kartini_4.txt...\n",
      "  -> Memproses file: Kelompok7_Pendidikan Dasar dan Menengah yang bermutu untuk seluruh rakyat.txt...\n",
      "     WARN: Jumlah kata cleaned (1046) != stemmed (1047) untuk file Kelompok7_Pendidikan Dasar dan Menengah yang bermutu untuk seluruh rakyat.txt. Proxy Stem Collision tidak dihitung.\n",
      "  -> Memproses file: Merawat Kartini di Kebun Nirkertas_9.txt...\n",
      "     WARN: Jumlah kata cleaned (754) != stemmed (760) untuk file Merawat Kartini di Kebun Nirkertas_9.txt. Proxy Stem Collision tidak dihitung.\n",
      "  -> Memproses file: Ragam Keluhan Mitra MBG Menalangi Biaya hingga Jual Barang Pribadi_Kel 1.txt...\n",
      "  -> Memproses file: AS Soroti QRIS & GPN dalam Negosiasi Dagang, Ini Alasannya_1.txt...\n",
      "  -> Memproses file: TKDN dan Negosiasi Dagang RI-AS_10.txt...\n",
      "  -> Memproses file: Robot Ikut Lomba Lari_4.txt...\n",
      "  -> Memproses file: Dilema Persalinan Caesar di Era JKN Antara Hak Ibu dan Efisiensi Anggaran_4.txt...\n",
      "     WARN: Jumlah kata cleaned (806) != stemmed (808) untuk file Dilema Persalinan Caesar di Era JKN Antara Hak Ibu dan Efisiensi Anggaran_4.txt. Proxy Stem Collision tidak dihitung.\n",
      "\n",
      "Proses cleaning dan stemming selesai.\n",
      "Jumlah file .txt yang diproses: 30\n",
      "Hasil perbandingan disimpan di: /home/xerces/project/stemming-project/output/sastrawi_comparison_stats\n",
      "Hasil cleaning saja disimpan di: /home/xerces/project/stemming-project/output/cleaned_stats\n",
      "Total waktu eksekusi: 73.06 detik\n",
      "\n",
      "--- Evaluasi Statistik TOTAL (Semua File) ---\n",
      "Total kata (tokens) original (semua file): 22977\n",
      "Jumlah kata unik (types) original (semua file): 6529\n",
      "------------------------------\n",
      "Total kata (tokens) setelah cleaning (semua file): 22565\n",
      "Jumlah kata unik (types) setelah cleaning (semua file): 4503\n",
      "------------------------------\n",
      "Total kata (tokens) setelah stemming (semua file): 22596\n",
      "Jumlah kata unik (types) setelah stemming (semua file): 3115\n",
      "------------------------------\n",
      "Total Proxy Stem Collision (semua file): 626\n",
      "------------------------------\n",
      "Persentase reduksi kosakata unik (Original -> Stemmed): 52.29%\n",
      "Persentase reduksi kosakata unik (Cleaned -> Stemmed): 30.82%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.Dictionary.ArrayDictionary import ArrayDictionary\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "# --- Konfigurasi ---\n",
    "NAMA_FOLDER_INPUT = 'input'\n",
    "NAMA_FILE_KAMUS_KUSTOM = \"kamus_kata_dasar.txt\"\n",
    "# Nama file output baru untuk menandakan ini simulasi\n",
    "NAMA_FOLDER_OUTPUT_COMPARISON_RELATIF = 'output/sastrawi_comparison_simulated_metrics'\n",
    "NAMA_FOLDER_OUTPUT_CLEANED_RELATIF = 'output/cleaned_simulated_metrics' # Opsional\n",
    "# --- Akhir Konfigurasi ---\n",
    "\n",
    "# Path Setup\n",
    "base_dir = os.getcwd()\n",
    "print(f\"Menggunakan direktori kerja saat ini sebagai basis: {base_dir}\")\n",
    "input_folder_path = os.path.join(base_dir, NAMA_FOLDER_INPUT)\n",
    "kamus_kustom_path = os.path.join(base_dir, NAMA_FILE_KAMUS_KUSTOM)\n",
    "output_folder_comparison_path = os.path.join(base_dir, NAMA_FOLDER_OUTPUT_COMPARISON_RELATIF)\n",
    "\n",
    "output_folder_cleaned_path = None\n",
    "if 'NAMA_FOLDER_OUTPUT_CLEANED_RELATIF' in locals() and NAMA_FOLDER_OUTPUT_CLEANED_RELATIF:\n",
    "    output_folder_cleaned_path = os.path.join(base_dir, NAMA_FOLDER_OUTPUT_CLEANED_RELATIF)\n",
    "\n",
    "# --- Fungsi Muat Kamus Kustom (sama) ---\n",
    "def muat_kamus_kustom(filepath):\n",
    "    kata_dasar_kustom = set()\n",
    "    # ... (isi fungsi sama seperti sebelumnya) ...\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                kata = line.strip().lower()\n",
    "                if kata:\n",
    "                    kata_dasar_kustom.add(kata)\n",
    "        if not kata_dasar_kustom:\n",
    "            raise ValueError(f\"File kamus kustom '{filepath}' ditemukan tapi kosong.\")\n",
    "        print(f\"Berhasil memuat {len(kata_dasar_kustom)} kata dari kamus kustom: {filepath}\")\n",
    "        return kata_dasar_kustom\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: File kamus kustom '{filepath}' tidak ditemukan!\")\n",
    "        raise\n",
    "    except ValueError as ve:\n",
    "        print(f\"ERROR: {ve}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Terjadi kesalahan tak terduga saat memuat kamus kustom: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# --- Fungsi Cleaning (sama) ---\n",
    "def bersihkan_teks_preserve_lines(teks):\n",
    "    # ... (isi fungsi sama seperti sebelumnya) ...\n",
    "    lines = teks.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    tanda_baca_escaped = re.escape(string.punctuation)\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        line = re.sub(r'[' + tanda_baca_escaped + ']', '', line)\n",
    "        line = re.sub(r'[ \\t]+', ' ', line)\n",
    "        line = line.strip()\n",
    "        cleaned_lines.append(line)\n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "# === 1. Muat Kamus Kustom & Inisialisasi Stemmer ===\n",
    "try:\n",
    "    print(f\"Mencoba memuat kamus kustom dari: {kamus_kustom_path}...\")\n",
    "    kamus_set_kustom = muat_kamus_kustom(kamus_kustom_path)\n",
    "    print(\"Menginisialisasi stemmer Sastrawi DENGAN KAMUS KUSTOM...\")\n",
    "    custom_dictionary = ArrayDictionary(list(kamus_set_kustom))\n",
    "    factory = StemmerFactory(custom_dictionary)\n",
    "    stemmer = factory.create_stemmer() # Ini stemmer yang akan kita evaluasi\n",
    "    print(\"Stemmer dengan kamus kustom SIAP.\")\n",
    "except (FileNotFoundError, ValueError, Exception) as e:\n",
    "    print(f\"\\nGAGAL menginisialisasi stemmer: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# === Fungsi untuk Menghitung Metrik Simulasi ===\n",
    "def hitung_simulasi_metrik(list_kata_unik_cleaned, stemmer_obj, kamus_dasar_set):\n",
    "    \"\"\"\n",
    "    Menghitung simulasi MWC, UI, OI berdasarkan peta tiruan.\n",
    "    INGAT: Ini BUKAN evaluasi yang valid secara linguistik.\n",
    "    \"\"\"\n",
    "    simulated_gold_map = {} # Peta tiruan: kata_cleaned -> stem_anggap_benar\n",
    "    sastrawi_results = {}   # Peta hasil: kata_cleaned -> stem_hasil_sastrawi\n",
    "\n",
    "    # 1. Bangun peta tiruan dan dapatkan hasil Sastrawi\n",
    "    for kata in list_kata_unik_cleaned:\n",
    "        if not kata: continue # Lewati string kosong\n",
    "\n",
    "        hasil_stem = stemmer_obj.stem(kata)\n",
    "        sastrawi_results[kata] = hasil_stem\n",
    "\n",
    "        # Buat entri untuk peta tiruan \"gold standard\"\n",
    "        if kata in kamus_dasar_set:\n",
    "            simulated_gold_map[kata] = kata # Jika kata dasar, stem benarnya = dirinya sendiri\n",
    "        else:\n",
    "            # Asumsi KRUSIAL: anggap hasil stemmer BENAR untuk kata non-dasar\n",
    "            simulated_gold_map[kata] = hasil_stem\n",
    "\n",
    "    # 2. Hitung Metrik Simulasi\n",
    "    mwc_sim = 0\n",
    "    oi_sim_groups_error = 0\n",
    "    ui_sim_groups_error = 0\n",
    "\n",
    "    # MWC Simulasi\n",
    "    for kata, stem_sastrawi in sastrawi_results.items():\n",
    "        # Bandingkan dengan peta tiruan\n",
    "        if kata in simulated_gold_map and stem_sastrawi != simulated_gold_map[kata]:\n",
    "            mwc_sim += 1\n",
    "            # Seharusnya mwc_sim akan ~0 karena cara peta tiruan dibuat\n",
    "\n",
    "    # UI/OI Simulasi - Kelompokkan berdasarkan peta tiruan dan hasil sastrawi\n",
    "    gold_groups = defaultdict(set)\n",
    "    sastrawi_groups = defaultdict(set)\n",
    "\n",
    "    for kata, stem_anggap_benar in simulated_gold_map.items():\n",
    "        gold_groups[stem_anggap_benar].add(kata)\n",
    "        # Pastikan kata ada di hasil sastrawi (seharusnya selalu ada)\n",
    "        if kata in sastrawi_results:\n",
    "            sastrawi_groups[sastrawi_results[kata]].add(kata)\n",
    "\n",
    "    # Hitung UI Simulasi (Kelompok \"benar\" yang dipecah Sastrawi)\n",
    "    for stem_anggap_benar, kata_di_gold_group in gold_groups.items():\n",
    "        if not kata_di_gold_group: continue\n",
    "        hasil_sastrawi_untuk_grup = {sastrawi_results.get(k) for k in kata_di_gold_group if k in sastrawi_results}\n",
    "        # Hapus None jika ada kata yg tdk terproses (jarang terjadi)\n",
    "        hasil_sastrawi_untuk_grup.discard(None)\n",
    "        if len(hasil_sastrawi_untuk_grup) > 1:\n",
    "            ui_sim_groups_error += 1\n",
    "\n",
    "    # Hitung OI Simulasi (Kelompok Sastrawi yang mencampur kata dari grup \"benar\" berbeda)\n",
    "    for stem_sastrawi, kata_di_sastrawi_group in sastrawi_groups.items():\n",
    "        if not kata_di_sastrawi_group: continue\n",
    "        asal_anggap_benar_untuk_grup = {simulated_gold_map.get(k) for k in kata_di_sastrawi_group if k in simulated_gold_map}\n",
    "        asal_anggap_benar_untuk_grup.discard(None)\n",
    "        if len(asal_anggap_benar_untuk_grup) > 1:\n",
    "            oi_sim_groups_error += 1\n",
    "\n",
    "    return mwc_sim, ui_sim_groups_error, oi_sim_groups_error\n",
    "# =============================================\n",
    "\n",
    "# 2. Buat folder output (sama)\n",
    "# ... (kode pembuatan folder) ...\n",
    "if not os.path.exists(output_folder_comparison_path): os.makedirs(output_folder_comparison_path); print(f\"Folder output dibuat: {output_folder_comparison_path}\")\n",
    "else: print(f\"Folder output sudah ada: {output_folder_comparison_path}\")\n",
    "if output_folder_cleaned_path:\n",
    "    if not os.path.exists(output_folder_cleaned_path): os.makedirs(output_folder_cleaned_path); print(f\"Folder dibuat: {output_folder_cleaned_path}\")\n",
    "    else: print(f\"Folder sudah ada: {output_folder_cleaned_path}\")\n",
    "\n",
    "\n",
    "# Variabel Evaluasi TOTAL\n",
    "# ... (variabel statistik dasar) ...\n",
    "total_words_original_all_files = 0; total_words_cleaned_all_files = 0; total_words_stemmed_all_files = 0\n",
    "unique_words_original_total = set(); unique_words_cleaned_total = set(); unique_words_stemmed_total = set()\n",
    "# Variabel Total untuk Metrik Simulasi\n",
    "total_mwc_sim_all_files = 0\n",
    "total_ui_sim_all_files = 0\n",
    "total_oi_sim_all_files = 0\n",
    "\n",
    "# 3. Proses setiap file\n",
    "print(f\"\\nMemulai proses cleaning dan stemming dari folder: {input_folder_path}\")\n",
    "print(f\"Menggunakan KAMUS KUSTOM: {kamus_kustom_path}\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # ... (kode cek folder input, list file) ...\n",
    "    if not os.path.isdir(input_folder_path): raise FileNotFoundError(f\"Folder input '{input_folder_path}' tidak ditemukan.\")\n",
    "    list_file = os.listdir(input_folder_path); processed_files = 0; skipped_files = 0\n",
    "    if not list_file: print(\"Folder input kosong.\")\n",
    "\n",
    "    for filename in list_file:\n",
    "        # ... (kode path file) ...\n",
    "        input_file_path = os.path.join(input_folder_path, filename)\n",
    "        if os.path.isfile(input_file_path) and filename.lower().endswith('.txt'):\n",
    "            output_file_comparison_path = os.path.join(output_folder_comparison_path, filename)\n",
    "            current_output_cleaned_path = None\n",
    "            if output_folder_cleaned_path: current_output_cleaned_path = os.path.join(output_folder_cleaned_path, filename)\n",
    "\n",
    "            print(f\"  -> Memproses file: {filename}...\")\n",
    "\n",
    "            try:\n",
    "                # ... (baca file, statistik original) ...\n",
    "                with open(input_file_path, 'r', encoding='utf-8', errors='ignore') as f_in: original_text = f_in.read()\n",
    "                original_words_list = original_text.split(); count_original_words = len(original_words_list)\n",
    "                set_unique_original = set(w for w in original_words_list if w); count_unique_original = len(set_unique_original)\n",
    "\n",
    "                # ... (cleaning, opsional simpan cleaned) ...\n",
    "                cleaned_text = bersihkan_teks_preserve_lines(original_text)\n",
    "                if current_output_cleaned_path:\n",
    "                    with open(current_output_cleaned_path, 'w', encoding='utf-8') as f_clean: f_clean.write(cleaned_text)\n",
    "\n",
    "                # Stemming\n",
    "                stemmed_text = stemmer.stem(cleaned_text)\n",
    "\n",
    "                # Statistik Dasar Cleaned & Stemmed\n",
    "                valid_cleaned_words = [w for w in cleaned_text.split() if w]\n",
    "                valid_stemmed_words = [w for w in stemmed_text.split() if w]\n",
    "                count_cleaned_words = len(valid_cleaned_words)\n",
    "                set_unique_cleaned = set(valid_cleaned_words); count_unique_cleaned = len(set_unique_cleaned)\n",
    "                count_stemmed_words = len(valid_stemmed_words)\n",
    "                set_unique_stemmed = set(valid_stemmed_words); count_unique_stemmed = len(set_unique_stemmed)\n",
    "\n",
    "                # *** Hitung Metrik SIMULASI untuk file ini ***\n",
    "                # Kita butuh daftar kata unik yang bersih sebagai input\n",
    "                list_unik_cleaned = list(set_unique_cleaned)\n",
    "                mwc_sim_file, ui_sim_file, oi_sim_file = hitung_simulasi_metrik(\n",
    "                    list_unik_cleaned, stemmer, kamus_set_kustom\n",
    "                )\n",
    "                # ********************************************\n",
    "\n",
    "                # Update Total Simulasi\n",
    "                total_mwc_sim_all_files += mwc_sim_file\n",
    "                total_ui_sim_all_files += ui_sim_file\n",
    "                total_oi_sim_all_files += oi_sim_file\n",
    "\n",
    "                # Buat Header File Output (dengan metrik simulasi)\n",
    "                file_header = f\"\"\"=============================================\n",
    "FILE: {filename} - STATISTIK (Kamus Kustom: {os.path.basename(kamus_kustom_path)})\n",
    "=============================================\n",
    "A. STATISTIK DASAR:\n",
    "   Jumlah Kata (Original): {count_original_words}\n",
    "   Jumlah Kata Unik (Original): {count_unique_original}\n",
    "   ------------------------------------------\n",
    "   Jumlah Kata (Setelah Cleaning): {count_cleaned_words}\n",
    "   Jumlah Kata Unik (Setelah Cleaning): {count_unique_cleaned}\n",
    "   ------------------------------------------\n",
    "   Jumlah Kata (Setelah Stemming): {count_stemmed_words}\n",
    "   Jumlah Kata Unik (Setelah Stemming): {count_unique_stemmed}\n",
    "---------------------------------------------\n",
    "B. METRIK EVALUASI SIMULASI (PERKIRAAN SANGAT KASAR!):\n",
    "   Simulated MWC (Mis-stemmed*): {mwc_sim_file}\n",
    "   Simulated UI (Under-stemming Groups**): {ui_sim_file}\n",
    "   Simulated OI (Over-stemming Groups***): {oi_sim_file}\n",
    "=============================================\n",
    "CATATAN SANGAT PENTING:\n",
    "Angka MWC, UI, OI di atas adalah HASIL SIMULASI berdasarkan asumsi bahwa\n",
    "hasil stemmer dianggap 'benar' jika kata input tidak ada di kamus dasar.\n",
    "Ini BUKAN evaluasi linguistik yang valid dan TIDAK MENGGUNAKAN GOLD STANDARD\n",
    "STEMMING yang sebenarnya. Gunakan HANYA untuk perbandingan relatif kasar\n",
    "dalam eksperimen internal Anda.\n",
    "*   Simulated MWC: Jumlah kata unik yang stem hasil Sastrawi != stem 'benar'\n",
    "    menurut peta tiruan (kemungkinan selalu 0).\n",
    "**  Simulated UI: Jumlah kelompok stem 'benar' (dari peta tiruan) yang\n",
    "    hasil stem Sastrawi-nya terpecah menjadi >1 stem berbeda.\n",
    "*** Simulated OI: Jumlah kelompok stem hasil Sastrawi yang berisi kata-kata\n",
    "    yang berasal dari >1 stem 'benar' berbeda (menurut peta tiruan).\n",
    "\n",
    "-> Interpretasikan angka Simulasi MWC, UI, OI dengan SANGAT HATI-HATI! <-\n",
    "\n",
    "\"\"\"\n",
    "                separator_cleaned = \"\\n--- TEKS SETELAH CLEANING (SEBELUM STEMMING) ---\\n\"\n",
    "                separator_stemmed = \"\\n\\n--- TEKS SETELAH STEMMING ---\\n\"\n",
    "                final_comparison_content = (file_header + separator_cleaned + cleaned_text + separator_stemmed + stemmed_text)\n",
    "\n",
    "                # ... (tulis file perbandingan) ...\n",
    "                with open(output_file_comparison_path, 'w', encoding='utf-8') as f_comparison: f_comparison.write(final_comparison_content)\n",
    "\n",
    "                # Update Statistik TOTAL Dasar\n",
    "                total_words_original_all_files += count_original_words; unique_words_original_total.update(set_unique_original)\n",
    "                total_words_cleaned_all_files += count_cleaned_words; unique_words_cleaned_total.update(set_unique_cleaned)\n",
    "                total_words_stemmed_all_files += count_stemmed_words; unique_words_stemmed_total.update(set_unique_stemmed)\n",
    "                processed_files += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"     ERROR saat memproses file {filename}: {e}\")\n",
    "        else:\n",
    "            # ... (log skip file) ...\n",
    "            if os.path.isfile(input_file_path): print(f\"  -> Melewati file non-txt: {filename}\")\n",
    "            elif os.path.exists(input_file_path): print(f\"  -> Melewati item non-file: {filename}\")\n",
    "            else: print(f\"  -> Path tidak valid: {filename}\")\n",
    "            skipped_files += 1\n",
    "\n",
    "    end_time = time.time(); total_time = end_time - start_time\n",
    "\n",
    "    # ... (print status selesai) ...\n",
    "    print(f\"\\nProses SELESAI (Kamus Kustom, Metrik Simulasi).\")\n",
    "    print(f\"Jumlah file .txt diproses: {processed_files}\")\n",
    "    if skipped_files > 0: print(f\"Jumlah item dilewati: {skipped_files}\")\n",
    "    print(f\"Hasil perbandingan disimpan di: {output_folder_comparison_path}\")\n",
    "    if output_folder_cleaned_path and os.path.exists(output_folder_cleaned_path): print(f\"Hasil cleaning saja disimpan di: {output_folder_cleaned_path}\")\n",
    "    print(f\"Total waktu eksekusi: {total_time:.2f} detik\")\n",
    "\n",
    "    # Cetak Statistik TOTAL dengan Metrik Simulasi\n",
    "    print(\"\\n--- Statistik TOTAL (Semua File - Kamus Kustom - TERMASUK SIMULASI METRIK) ---\")\n",
    "    count_unique_original_total = len(unique_words_original_total); count_unique_cleaned_total = len(unique_words_cleaned_total); count_unique_stemmed_total = len(unique_words_stemmed_total)\n",
    "    print(f\"Total kata (tokens) original: {total_words_original_all_files}\"); print(f\"Jumlah kata unik (types) original: {count_unique_original_total}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total kata (tokens) cleaned: {total_words_cleaned_all_files}\"); print(f\"Jumlah kata unik (types) cleaned: {count_unique_cleaned_total}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total kata (tokens) stemmed: {total_words_stemmed_all_files}\"); print(f\"Jumlah kata unik (types) stemmed: {count_unique_stemmed_total}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"METRIK EVALUASI SIMULASI TOTAL (PERKIRAAN SANGAT KASAR):\")\n",
    "    print(f\"  Total Simulated MWC: {total_mwc_sim_all_files}\")\n",
    "    print(f\"  Total Simulated UI Groups: {total_ui_sim_all_files}\")\n",
    "    print(f\"  Total Simulated OI Groups: {total_oi_sim_all_files}\")\n",
    "    print(\"-\" * 30)\n",
    "    # ... (print persentase reduksi) ...\n",
    "    if count_unique_original_total > 0: reduction_from_original = ((count_unique_original_total - count_unique_stemmed_total) / count_unique_original_total) * 100; print(f\"Reduksi kosakata unik (Original -> Stemmed): {reduction_from_original:.2f}%\")\n",
    "    if count_unique_cleaned_total > 0: reduction_from_cleaned = ((count_unique_cleaned_total - count_unique_stemmed_total) / count_unique_cleaned_total) * 100; print(f\"Reduksi kosakata unik (Cleaned -> Stemmed): {reduction_from_cleaned:.2f}%\")\n",
    "\n",
    "except FileNotFoundError as fnf_error: print(f\"ERROR: {fnf_error}\"); print(\"Pastikan folder input ada.\")\n",
    "except Exception as e: print(f\"Terjadi kesalahan umum: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
