{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5102882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Import Stemmer ---\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.Dictionary.ArrayDictionary import ArrayDictionary\n",
    "import nltk\n",
    "try:\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    nltk.data.find('tokenizers/punkt') # Cek jika 'punkt' ada\n",
    "except LookupError:\n",
    "    print(\"NLTK 'punkt' resource not found. Downloading...\")\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "# --------------------\n",
    "\n",
    "# --- KONFIGURASI ---\n",
    "# Folder Input\n",
    "INPUT_FOLDER_INDO = 'input/indo'\n",
    "INPUT_FOLDER_ENG = 'input/eng'\n",
    "\n",
    "# Folder Output\n",
    "OUTPUT_FOLDER_INDO_COMPARE = 'output/indo_comparison_simulated'\n",
    "OUTPUT_FOLDER_ENG_COMPARE = 'output/eng_comparison_simulated'\n",
    "OUTPUT_FOLDER_INDO_STEMMED = 'output/indo_stemmed' # Untuk IR\n",
    "OUTPUT_FOLDER_ENG_STEMMED = 'output/eng_stemmed'   # Untuk IR\n",
    "\n",
    "# Kamus Kata Dasar Kustom (dari gambar Anda)\n",
    "# Pastikan semua lowercase\n",
    "root_words_custom = set([\n",
    "    \"politik\", \"ekonomi\", \"olahraga\", \"kesehatan\", \"pendidikan\",\n",
    "    \"sakit\", \"ajar\", \"main\", \"sehat\", \"kerja\", \"didik\", \"guna\", \"pakai\",\n",
    "    \"tahu\", \"percaya\", \"ubah\", \"kaji\", \"nilai\", \"teknologi\", \"finance\",\n",
    "    \"government\", \"education\", \"sport\", \"health\", \"play\", \"study\", \"run\"\n",
    "])\n",
    "# --------------------\n",
    "\n",
    "# --- Fungsi Helper ---\n",
    "\n",
    "def bersihkan_teks_preserve_lines(teks):\n",
    "    \"\"\"Membersihkan teks per baris sambil mempertahankan newline.\"\"\"\n",
    "    lines = teks.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    # Hapus tanda baca kecuali apostrof tunggal dalam kata (opsional)\n",
    "    # punctuation_to_remove = string.punctuation.replace(\"'\", \"\")\n",
    "    # tanda_baca_escaped = re.escape(punctuation_to_remove)\n",
    "    tanda_baca_escaped = re.escape(string.punctuation) # Versi simpel\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line) # Hapus angka\n",
    "        line = re.sub(r'[' + tanda_baca_escaped + ']', '', line) # Hapus tanda baca\n",
    "        line = re.sub(r'[ \\t]+', ' ', line) # Spasi/tab berlebih jadi satu\n",
    "        line = line.strip() # Spasi awal/akhir baris\n",
    "        cleaned_lines.append(line)\n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "def hitung_simulasi_metrik(list_kata_unik_cleaned, stemmer_obj, kamus_dasar_set):\n",
    "    \"\"\"\n",
    "    Menghitung simulasi MWC, UI, OI berdasarkan peta tiruan.\n",
    "    INGAT: Ini BUKAN evaluasi yang valid secara linguistik.\n",
    "    \"\"\"\n",
    "    simulated_gold_map = {}\n",
    "    sastrawi_results = {}\n",
    "    is_sastrawi = isinstance(stemmer_obj, nltk.stem.api.StemmerI) # Cek tipe stemmer (kurang ideal, tapi untuk contoh)\n",
    "                                                                  # Atau cek berdasarkan bahasa saja\n",
    "\n",
    "    # Bangun peta tiruan dan hasil stemmer\n",
    "    for kata in list_kata_unik_cleaned:\n",
    "        if not kata: continue\n",
    "        hasil_stem = stemmer_obj.stem(kata)\n",
    "        sastrawi_results[kata] = hasil_stem\n",
    "\n",
    "        if kata in kamus_dasar_set:\n",
    "            simulated_gold_map[kata] = kata\n",
    "        else:\n",
    "            # Asumsi krusial: anggap hasil stemmer BENAR untuk kata non-dasar\n",
    "            simulated_gold_map[kata] = hasil_stem\n",
    "\n",
    "    mwc_sim = 0; oi_sim_groups_error = 0; ui_sim_groups_error = 0\n",
    "    gold_groups = defaultdict(set); sastrawi_groups = defaultdict(set)\n",
    "\n",
    "    for kata, stem_anggap_benar in simulated_gold_map.items():\n",
    "        gold_groups[stem_anggap_benar].add(kata)\n",
    "        if kata in sastrawi_results:\n",
    "            sastrawi_groups[sastrawi_results[kata]].add(kata)\n",
    "            if sastrawi_results[kata] != stem_anggap_benar:\n",
    "                 mwc_sim += 1 # MWC (tiruan): hasil beda dari peta tiruan\n",
    "\n",
    "    for stem_anggap_benar, kata_di_gold_group in gold_groups.items():\n",
    "        if not kata_di_gold_group: continue\n",
    "        hasil_sastrawi_untuk_grup = {sastrawi_results.get(k) for k in kata_di_gold_group if k in sastrawi_results}\n",
    "        hasil_sastrawi_untuk_grup.discard(None)\n",
    "        if len(hasil_sastrawi_untuk_grup) > 1:\n",
    "            ui_sim_groups_error += 1 # UI (tiruan): kelompok 'benar' dipecah\n",
    "\n",
    "    for stem_sastrawi, kata_di_sastrawi_group in sastrawi_groups.items():\n",
    "        if not kata_di_sastrawi_group: continue\n",
    "        asal_anggap_benar_untuk_grup = {simulated_gold_map.get(k) for k in kata_di_sastrawi_group if k in simulated_gold_map}\n",
    "        asal_anggap_benar_untuk_grup.discard(None)\n",
    "        if len(asal_anggap_benar_untuk_grup) > 1:\n",
    "            oi_sim_groups_error += 1 # OI (tiruan): kelompok hasil mencampur asal 'benar' yg beda\n",
    "\n",
    "    return mwc_sim, ui_sim_groups_error, oi_sim_groups_error\n",
    "\n",
    "def proses_dokumen_set(input_folder, output_folder_compare, output_folder_stemmed, stemmer_obj, kamus_dasar_set, language_name):\n",
    "    \"\"\"Memproses satu set dokumen (Indo atau Eng).\"\"\"\n",
    "    print(f\"\\n--- Memproses Dokumen Bahasa: {language_name} ---\")\n",
    "    print(f\"Input: {input_folder}\")\n",
    "    print(f\"Output Perbandingan: {output_folder_compare}\")\n",
    "    print(f\"Output Stemmed (IR): {output_folder_stemmed}\")\n",
    "\n",
    "    # Buat folder output jika belum ada\n",
    "    os.makedirs(output_folder_compare, exist_ok=True)\n",
    "    os.makedirs(output_folder_stemmed, exist_ok=True)\n",
    "\n",
    "    # Variabel Akumulasi Statistik untuk set ini\n",
    "    total_stats = {\n",
    "        'original_words': 0, 'cleaned_words': 0, 'stemmed_words': 0,\n",
    "        'unique_original': set(), 'unique_cleaned': set(), 'unique_stemmed': set(),\n",
    "        'mwc_sim': 0, 'ui_sim': 0, 'oi_sim': 0,\n",
    "        'processed_files': 0, 'skipped_files': 0\n",
    "    }\n",
    "\n",
    "    if not os.path.isdir(input_folder):\n",
    "        print(f\"WARNING: Folder input '{input_folder}' tidak ditemukan. Melewati set ini.\")\n",
    "        return total_stats # Kembalikan stats kosong\n",
    "\n",
    "    try:\n",
    "        list_file = os.listdir(input_folder)\n",
    "        if not list_file:\n",
    "            print(\"Folder input kosong.\")\n",
    "            return total_stats\n",
    "\n",
    "        for filename in list_file:\n",
    "            input_file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            if os.path.isfile(input_file_path) and filename.lower().endswith('.txt'):\n",
    "                output_file_compare_path = os.path.join(output_folder_compare, filename)\n",
    "                output_file_stemmed_path = os.path.join(output_folder_stemmed, filename)\n",
    "\n",
    "                print(f\"  -> Memproses: {filename}...\")\n",
    "                try:\n",
    "                    with open(input_file_path, 'r', encoding='utf-8', errors='ignore') as f_in:\n",
    "                        original_text = f_in.read()\n",
    "\n",
    "                    # Statistik Original\n",
    "                    original_words_list = original_text.split()\n",
    "                    count_original_words = len(original_words_list)\n",
    "                    set_unique_original = set(w for w in original_words_list if w)\n",
    "                    count_unique_original = len(set_unique_original)\n",
    "\n",
    "                    # Cleaning\n",
    "                    cleaned_text = bersihkan_teks_preserve_lines(original_text)\n",
    "\n",
    "                    # Stemming\n",
    "                    stemmed_text = stemmer_obj.stem(cleaned_text) # Gunakan stemmer yang sesuai\n",
    "\n",
    "                    # Simpan HANYA stemmed text untuk IR\n",
    "                    with open(output_file_stemmed_path, 'w', encoding='utf-8') as f_stem_out:\n",
    "                        f_stem_out.write(stemmed_text)\n",
    "\n",
    "                    # Statistik Dasar Cleaned & Stemmed\n",
    "                    valid_cleaned_words = [w for w in cleaned_text.split() if w]\n",
    "                    valid_stemmed_words = [w for w in stemmed_text.split() if w]\n",
    "                    count_cleaned_words = len(valid_cleaned_words)\n",
    "                    set_unique_cleaned = set(valid_cleaned_words); count_unique_cleaned = len(set_unique_cleaned)\n",
    "                    count_stemmed_words = len(valid_stemmed_words)\n",
    "                    set_unique_stemmed = set(valid_stemmed_words); count_unique_stemmed = len(set_unique_stemmed)\n",
    "\n",
    "                    # Hitung Metrik Simulasi\n",
    "                    list_unik_cleaned = list(set_unique_cleaned)\n",
    "                    mwc_sim_file, ui_sim_file, oi_sim_file = hitung_simulasi_metrik(\n",
    "                        list_unik_cleaned, stemmer_obj, kamus_dasar_set\n",
    "                    )\n",
    "\n",
    "                    # Buat Header File Output Perbandingan\n",
    "                    file_header = f\"\"\"=============================================\n",
    "FILE: {filename} - STATISTIK & METRIK SIMULASI ({language_name})\n",
    "=============================================\n",
    "A. STATISTIK DASAR:\n",
    "   Jumlah Kata (Original): {count_original_words}\n",
    "   Jumlah Kata Unik (Original): {count_unique_original}\n",
    "   ------------------------------------------\n",
    "   Jumlah Kata (Setelah Cleaning): {count_cleaned_words}\n",
    "   Jumlah Kata Unik (Setelah Cleaning): {count_unique_cleaned}\n",
    "   ------------------------------------------\n",
    "   Jumlah Kata (Setelah Stemming): {count_stemmed_words}\n",
    "   Jumlah Kata Unik (Setelah Stemming): {count_unique_stemmed}\n",
    "---------------------------------------------\n",
    "B. METRIK EVALUASI SIMULASI (PERKIRAAN SANGAT KASAR!):\n",
    "   Simulated MWC (Mis-stemmed*): {mwc_sim_file}\n",
    "   Simulated UI (Under-stemming Groups**): {ui_sim_file}\n",
    "   Simulated OI (Over-stemming Groups***): {oi_sim_file}\n",
    "=============================================\n",
    "CATATAN SANGAT PENTING:\n",
    "Metrik MWC, UI, OI di atas adalah HASIL SIMULASI berdasarkan kamus dasar kustom\n",
    "dan asumsi internal. Ini BUKAN evaluasi linguistik yang valid. Gunakan HANYA\n",
    "untuk perbandingan relatif kasar. (Lihat definisi di kode sumber).\n",
    "\n",
    "-> Interpretasikan angka Simulasi MWC, UI, OI dengan SANGAT HATI-HATI! <-\n",
    "\n",
    "\"\"\"\n",
    "                    separator_cleaned = \"\\n--- TEKS SETELAH CLEANING (SEBELUM STEMMING) ---\\n\"\n",
    "                    separator_stemmed = \"\\n\\n--- TEKS SETELAH STEMMING ---\\n\"\n",
    "                    final_comparison_content = (file_header + separator_cleaned + cleaned_text + separator_stemmed + stemmed_text)\n",
    "\n",
    "                    # Tulis file perbandingan\n",
    "                    with open(output_file_compare_path, 'w', encoding='utf-8') as f_comparison:\n",
    "                        f_comparison.write(final_comparison_content)\n",
    "\n",
    "                    # Akumulasi Statistik Total\n",
    "                    total_stats['original_words'] += count_original_words\n",
    "                    total_stats['cleaned_words'] += count_cleaned_words\n",
    "                    total_stats['stemmed_words'] += count_stemmed_words\n",
    "                    total_stats['unique_original'].update(set_unique_original)\n",
    "                    total_stats['unique_cleaned'].update(set_unique_cleaned)\n",
    "                    total_stats['unique_stemmed'].update(set_unique_stemmed)\n",
    "                    total_stats['mwc_sim'] += mwc_sim_file\n",
    "                    total_stats['ui_sim'] += ui_sim_file\n",
    "                    total_stats['oi_sim'] += oi_sim_file\n",
    "                    total_stats['processed_files'] += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"     ERROR saat memproses file {filename}: {e}\")\n",
    "            else:\n",
    "                # Log skip file\n",
    "                if os.path.isfile(input_file_path): print(f\"  -> Melewati file non-txt: {filename}\")\n",
    "                elif os.path.exists(input_file_path): print(f\"  -> Melewati item non-file: {filename}\")\n",
    "                else: print(f\"  -> Path tidak valid: {filename}\")\n",
    "                total_stats['skipped_files'] += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"WARNING: Folder input '{input_folder}' tidak ditemukan.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saat memproses folder {input_folder}: {e}\")\n",
    "\n",
    "    print(f\"--- Selesai memproses {language_name} ---\")\n",
    "    return total_stats\n",
    "\n",
    "def cari_dokumen(query, language, stemmed_docs_folder, stemmer_obj, top_n=5):\n",
    "    \"\"\"Mencari dokumen berdasarkan query yang di-stem.\"\"\"\n",
    "    print(f\"\\n--- Mencari Dokumen ({language}) untuk Query: '{query}' ---\")\n",
    "    if not os.path.isdir(stemmed_docs_folder):\n",
    "        print(f\"ERROR: Folder dokumen stemmed '{stemmed_docs_folder}' tidak ditemukan.\")\n",
    "        return []\n",
    "\n",
    "    # 1. Bersihkan dan stem query\n",
    "    cleaned_query = bersihkan_teks_preserve_lines(query)\n",
    "    query_stems = set(w for w in stemmer_obj.stem(cleaned_query).split() if w)\n",
    "    if not query_stems:\n",
    "        print(\"Query tidak menghasilkan stem yang valid setelah dibersihkan.\")\n",
    "        return []\n",
    "    print(f\"Stem Query: {query_stems}\")\n",
    "\n",
    "    # 2. Hitung skor relevansi (simple matching count)\n",
    "    doc_scores = {}\n",
    "    try:\n",
    "        for filename in os.listdir(stemmed_docs_folder):\n",
    "            if filename.lower().endswith('.txt'):\n",
    "                filepath = os.path.join(stemmed_docs_folder, filename)\n",
    "                try:\n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        stemmed_content = f.read()\n",
    "                        doc_stems = set(w for w in stemmed_content.split() if w)\n",
    "\n",
    "                        # Hitung jumlah stem query yang ada di dokumen\n",
    "                        score = len(query_stems.intersection(doc_stems))\n",
    "                        if score > 0:\n",
    "                            doc_scores[filename] = score\n",
    "                except Exception as e:\n",
    "                    print(f\"  Warning: Gagal membaca/memproses file stemmed {filename}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saat mengakses folder stemmed {stemmed_docs_folder}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 3. Urutkan dokumen berdasarkan skor\n",
    "    sorted_docs = sorted(doc_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # 4. Kembalikan top N\n",
    "    print(f\"Dokumen teratas yang relevan (Top {top_n}):\")\n",
    "    if not sorted_docs:\n",
    "        print(\"Tidak ada dokumen yang cocok ditemukan.\")\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for i, (doc, score) in enumerate(sorted_docs[:top_n]):\n",
    "        print(f\"{i+1}. {doc} (Skor: {score})\")\n",
    "        results.append((doc, score))\n",
    "    return results\n",
    "\n",
    "# --- PROGRAM UTAMA ---\n",
    "if __name__ == \"__main__\":\n",
    "    start_pipeline_time = time.time()\n",
    "\n",
    "    # Inisialisasi Stemmer\n",
    "    print(\"--- Inisialisasi Stemmer ---\")\n",
    "    try:\n",
    "        # Sastrawi dengan kamus kustom\n",
    "        sastrawi_custom_dict = ArrayDictionary(list(root_words_custom))\n",
    "        sastrawi_factory = StemmerFactory(sastrawi_custom_dict)\n",
    "        sastrawi_stemmer = sastrawi_factory.create_stemmer()\n",
    "        print(\"Stemmer Sastrawi (Kamus Kustom) siap.\")\n",
    "\n",
    "        # Snowball untuk Inggris\n",
    "        snowball_stemmer = SnowballStemmer('english')\n",
    "        print(\"Stemmer Snowball (English) siap.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Gagal menginisialisasi stemmer: {e}\")\n",
    "        sys.exit(1)\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    # Proses Dokumen Indonesia\n",
    "    stats_indo = proses_dokumen_set(\n",
    "        INPUT_FOLDER_INDO,\n",
    "        OUTPUT_FOLDER_INDO_COMPARE,\n",
    "        OUTPUT_FOLDER_INDO_STEMMED,\n",
    "        sastrawi_stemmer,\n",
    "        root_words_custom, # Kamus dasar digunakan untuk perhitungan metrik simulasi\n",
    "        \"Indonesia\"\n",
    "    )\n",
    "\n",
    "    # Proses Dokumen Inggris\n",
    "    stats_eng = proses_dokumen_set(\n",
    "        INPUT_FOLDER_ENG,\n",
    "        OUTPUT_FOLDER_ENG_COMPARE,\n",
    "        OUTPUT_FOLDER_ENG_STEMMED,\n",
    "        snowball_stemmer,\n",
    "        root_words_custom, # Kamus dasar kustom (mungkin kurang relevan untuk Snowball, tapi dipakai untuk konsistensi simulasi)\n",
    "        \"English\"\n",
    "    )\n",
    "\n",
    "    # --- Ringkasan dan Perbandingan Statistik Total ---\n",
    "    print(\"\\n\\n--- RINGKASAN STATISTIK TOTAL & PERBANDINGAN ---\")\n",
    "\n",
    "    def print_stats_comparison(stats_indo, stats_eng):\n",
    "        total_files_indo = stats_indo['processed_files']\n",
    "        total_files_eng = stats_eng['processed_files']\n",
    "        print(f\"{'Metrik':<40} | {'Indonesia':<20} | {'English':<20}\")\n",
    "        print(\"-\" * 85)\n",
    "        print(f\"{'Jumlah Dokumen Diproses':<40} | {total_files_indo:<20} | {total_files_eng:<20}\")\n",
    "        print(f\"{'Jumlah Dokumen Dilewati':<40} | {stats_indo['skipped_files']:<20} | {stats_eng['skipped_files']:<20}\")\n",
    "        print(\"-\" * 85)\n",
    "        print(\"Statistik Kata (Total):\")\n",
    "        print(f\"{'  Total Kata Original':<38} | {stats_indo['original_words']:<20} | {stats_eng['original_words']:<20}\")\n",
    "        print(f\"{'  Total Kata Cleaned':<38} | {stats_indo['cleaned_words']:<20} | {stats_eng['cleaned_words']:<20}\")\n",
    "        print(f\"{'  Total Kata Stemmed':<38} | {stats_indo['stemmed_words']:<20} | {stats_eng['stemmed_words']:<20}\")\n",
    "        print(\"-\" * 85)\n",
    "        print(\"Statistik Kata Unik (Total):\")\n",
    "        unique_ori_indo = len(stats_indo['unique_original']); unique_ori_eng = len(stats_eng['unique_original'])\n",
    "        unique_clean_indo = len(stats_indo['unique_cleaned']); unique_clean_eng = len(stats_eng['unique_cleaned'])\n",
    "        unique_stem_indo = len(stats_indo['unique_stemmed']); unique_stem_eng = len(stats_eng['unique_stemmed'])\n",
    "        print(f\"{'  Unik Original':<38} | {unique_ori_indo:<20} | {unique_ori_eng:<20}\")\n",
    "        print(f\"{'  Unik Cleaned':<38} | {unique_clean_indo:<20} | {unique_clean_eng:<20}\")\n",
    "        print(f\"{'  Unik Stemmed':<38} | {unique_stem_indo:<20} | {unique_stem_eng:<20}\")\n",
    "        print(\"-\" * 85)\n",
    "        print(\"METRIK EVALUASI SIMULASI (Total - PERKIRAAN KASAR):\")\n",
    "        print(f\"{'  Total Simulated MWC':<38} | {stats_indo['mwc_sim']:<20} | {stats_eng['mwc_sim']:<20}\")\n",
    "        print(f\"{'  Total Simulated UI Groups':<38} | {stats_indo['ui_sim']:<20} | {stats_eng['ui_sim']:<20}\")\n",
    "        print(f\"{'  Total Simulated OI Groups':<38} | {stats_indo['oi_sim']:<20} | {stats_eng['oi_sim']:<20}\")\n",
    "        print(\"-\" * 85)\n",
    "        print(\"Rata-rata Metrik Simulasi per Dokumen (Jika > 0 dokumen):\")\n",
    "        avg_mwc_indo = stats_indo['mwc_sim'] / total_files_indo if total_files_indo else 0\n",
    "        avg_ui_indo = stats_indo['ui_sim'] / total_files_indo if total_files_indo else 0\n",
    "        avg_oi_indo = stats_indo['oi_sim'] / total_files_indo if total_files_indo else 0\n",
    "        avg_mwc_eng = stats_eng['mwc_sim'] / total_files_eng if total_files_eng else 0\n",
    "        avg_ui_eng = stats_eng['ui_sim'] / total_files_eng if total_files_eng else 0\n",
    "        avg_oi_eng = stats_eng['oi_sim'] / total_files_eng if total_files_eng else 0\n",
    "        print(f\"{'  Avg. Simulated MWC':<38} | {avg_mwc_indo:<20.2f} | {avg_mwc_eng:<20.2f}\")\n",
    "        print(f\"{'  Avg. Simulated UI Groups':<38} | {avg_ui_indo:<20.2f} | {avg_ui_eng:<20.2f}\")\n",
    "        print(f\"{'  Avg. Simulated OI Groups':<38} | {avg_oi_indo:<20.2f} | {avg_oi_eng:<20.2f}\")\n",
    "        print(\"-\" * 85)\n",
    "\n",
    "    print_stats_comparison(stats_indo, stats_eng)\n",
    "    print(\"PERINGATAN: Ingatlah bahwa Metrik MWC, UI, OI adalah simulasi kasar!\")\n",
    "\n",
    "    # --- Contoh Penggunaan Information Retrieval ---\n",
    "    print(\"\\n\\n--- CONTOH INFORMATION RETRIEVAL ---\")\n",
    "    contoh_query_indo = \"kajian tentang pendidikan teknologi\"\n",
    "    hasil_cari_indo = cari_dokumen(\n",
    "        contoh_query_indo,\n",
    "        \"Indonesia\",\n",
    "        OUTPUT_FOLDER_INDO_STEMMED,\n",
    "        sastrawi_stemmer,\n",
    "        top_n=3\n",
    "    )\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    contoh_query_eng = \"studies about health and education technology\"\n",
    "    hasil_cari_eng = cari_dokumen(\n",
    "        contoh_query_eng,\n",
    "        \"English\",\n",
    "        OUTPUT_FOLDER_ENG_STEMMED,\n",
    "        snowball_stemmer,\n",
    "        top_n=3\n",
    "    )\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "    end_pipeline_time = time.time()\n",
    "    print(f\"\\nTotal waktu eksekusi pipeline: {end_pipeline_time - start_pipeline_time:.2f} detik\")\n",
    "    print(\"Pipeline Selesai.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
