{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5102882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Import Stemmer ---\n",
    "try:\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    from Sastrawi.Dictionary.ArrayDictionary import ArrayDictionary\n",
    "except ImportError:\n",
    "    print(\"ERROR: Sastrawi library not found. Please install it: pip install sastrawi\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    import nltk\n",
    "    # Import SnowballStemmer di luar try agar selalu terdefinisi\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    # Cek resource 'punkt', coba download jika tidak ada\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        print(\"NLTK 'punkt' resource not found. Trying to download...\")\n",
    "        try:\n",
    "            nltk.download('punkt', quiet=True)\n",
    "            print(\"Download 'punkt' attempt finished.\")\n",
    "        except Exception as download_err:\n",
    "            print(f\"WARNING: Failed to download 'punkt': {download_err}\")\n",
    "            print(\"Script will continue, but some NLTK functions might fail later.\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: NLTK library not found. Please install it: pip install nltk\")\n",
    "    sys.exit(1)\n",
    "# --------------------\n",
    "\n",
    "# --- Import untuk Grafik ---\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    print(\"WARNING: matplotlib or numpy not found. Plotting will be disabled.\")\n",
    "    print(\"Install them with: pip install matplotlib numpy\")\n",
    "    plt = None # Setel ke None jika tidak ada\n",
    "    np = None\n",
    "# --------------------------\n",
    "\n",
    "# --- KONFIGURASI ---\n",
    "# Folder Input\n",
    "INPUT_FOLDER_INDO = 'input/indo'\n",
    "INPUT_FOLDER_ENG = 'input/eng'\n",
    "\n",
    "# Folder Output\n",
    "OUTPUT_FOLDER_INDO_COMPARE = 'output/indo_comparison_simulated'\n",
    "OUTPUT_FOLDER_ENG_COMPARE = 'output/eng_comparison_simulated'\n",
    "OUTPUT_FOLDER_INDO_STEMMED = 'output/indo_stemmed' # Untuk IR\n",
    "OUTPUT_FOLDER_ENG_STEMMED = 'output/eng_stemmed'   # Untuk IR\n",
    "OUTPUT_GRAPH_FILENAME = 'output/stemming_metrics_comparison.png' # Nama file grafik\n",
    "\n",
    "# Kamus Kata Dasar Kustom (dari gambar Anda, pastikan lowercase)\n",
    "root_words_custom = set([\n",
    "    \"politik\", \"ekonomi\", \"olahraga\", \"kesehatan\", \"pendidikan\",\n",
    "    \"sakit\", \"ajar\", \"main\", \"sehat\", \"kerja\", \"didik\", \"guna\", \"pakai\",\n",
    "    \"tahu\", \"percaya\", \"ubah\", \"kaji\", \"nilai\", \"teknologi\", \"finance\",\n",
    "    \"government\", \"education\", \"sport\", \"health\", \"play\", \"study\", \"run\"\n",
    "])\n",
    "print(f\"Menggunakan {len(root_words_custom)} kata dasar kustom.\")\n",
    "# --------------------\n",
    "\n",
    "# --- Fungsi Helper ---\n",
    "\n",
    "def bersihkan_teks_preserve_lines(teks):\n",
    "    \"\"\"Membersihkan teks per baris sambil mempertahankan struktur newline.\"\"\"\n",
    "    if not isinstance(teks, str): return \"\" # Handle non-string input\n",
    "    lines = teks.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    tanda_baca_escaped = re.escape(string.punctuation)\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line) # Hapus angka\n",
    "        line = re.sub(r'[' + tanda_baca_escaped + ']', '', line) # Hapus tanda baca\n",
    "        line = re.sub(r'[ \\t]+', ' ', line) # Spasi/tab berlebih jadi satu\n",
    "        line = line.strip() # Spasi awal/akhir baris\n",
    "        cleaned_lines.append(line)\n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "def hitung_simulasi_metrik(list_kata_unik_cleaned, stemmer_obj, kamus_dasar_set):\n",
    "    \"\"\"\n",
    "    Menghitung simulasi MWC, UI, OI berdasarkan peta tiruan.\n",
    "    INGAT: Ini BUKAN evaluasi yang valid secara linguistik.\n",
    "    \"\"\"\n",
    "    simulated_gold_map = {} # Peta tiruan: kata_cleaned -> stem_anggap_benar\n",
    "    sastrawi_results = {}   # Peta hasil: kata_cleaned -> stem_hasil_stemmer\n",
    "\n",
    "    # 1. Bangun peta tiruan dan dapatkan hasil Stemmer\n",
    "    for kata in list_kata_unik_cleaned:\n",
    "        # Pastikan tidak ada karakter aneh dan ketik ulang jika perlu\n",
    "        if not kata: continue\n",
    "\n",
    "        try: # Tambahkan try-except jika stemmer error pada kata tertentu\n",
    "            hasil_stem = stemmer_obj.stem(kata)\n",
    "        except Exception as stem_err:\n",
    "            print(f\"    Warning: Stemmer error pada kata '{kata}': {stem_err}\")\n",
    "            hasil_stem = kata # Jika error, anggap tidak berubah\n",
    "\n",
    "        sastrawi_results[kata] = hasil_stem\n",
    "\n",
    "        # Buat entri untuk peta tiruan \"gold standard\"\n",
    "        if kata in kamus_dasar_set:\n",
    "            simulated_gold_map[kata] = kata\n",
    "        else:\n",
    "            # Asumsi KRUSIAL: anggap hasil stemmer BENAR untuk kata non-dasar\n",
    "            simulated_gold_map[kata] = hasil_stem\n",
    "\n",
    "    # 2. Hitung Metrik Simulasi\n",
    "    mwc_sim = 0\n",
    "    oi_sim_groups_error = 0\n",
    "    ui_sim_groups_error = 0\n",
    "\n",
    "    # MWC Simulasi\n",
    "    for kata, stem_hasil in sastrawi_results.items():\n",
    "        if kata in simulated_gold_map and stem_hasil != simulated_gold_map[kata]:\n",
    "            mwc_sim += 1\n",
    "\n",
    "    # UI/OI Simulasi\n",
    "    gold_groups = defaultdict(set)\n",
    "    sastrawi_groups = defaultdict(set)\n",
    "\n",
    "    for kata, stem_anggap_benar in simulated_gold_map.items():\n",
    "        gold_groups[stem_anggap_benar].add(kata)\n",
    "        if kata in sastrawi_results:\n",
    "            sastrawi_groups[sastrawi_results[kata]].add(kata)\n",
    "\n",
    "    # Hitung UI Simulasi\n",
    "    for stem_anggap_benar, kata_di_gold_group in gold_groups.items():\n",
    "        if not kata_di_gold_group or len(kata_di_gold_group) <= 1: continue\n",
    "        hasil_sastrawi_untuk_grup = {sastrawi_results.get(k) for k in kata_di_gold_group if k in sastrawi_results}\n",
    "        hasil_sastrawi_untuk_grup.discard(None)\n",
    "        if len(hasil_sastrawi_untuk_grup) > 1:\n",
    "            ui_sim_groups_error += 1\n",
    "\n",
    "    # Hitung OI Simulasi\n",
    "    for stem_sastrawi, kata_di_sastrawi_group in sastrawi_groups.items():\n",
    "        if not kata_di_sastrawi_group or len(kata_di_sastrawi_group) <= 1: continue\n",
    "        asal_anggap_benar_untuk_grup = {simulated_gold_map.get(k) for k in kata_di_sastrawi_group if k in simulated_gold_map}\n",
    "        asal_anggap_benar_untuk_grup.discard(None)\n",
    "        if len(asal_anggap_benar_untuk_grup) > 1:\n",
    "            oi_sim_groups_error += 1\n",
    "\n",
    "    return mwc_sim, ui_sim_groups_error, oi_sim_groups_error\n",
    "\n",
    "def proses_dokumen_set(input_folder, output_folder_compare, output_folder_stemmed, stemmer_obj, kamus_dasar_set, language_name):\n",
    "    \"\"\"Memproses satu set dokumen (Indo atau Eng).\"\"\"\n",
    "    print(f\"\\n--- Memproses Dokumen Bahasa: {language_name} ---\")\n",
    "    print(f\"Input: {input_folder}\")\n",
    "    print(f\"Output Perbandingan: {output_folder_compare}\")\n",
    "    print(f\"Output Stemmed (IR): {output_folder_stemmed}\")\n",
    "\n",
    "    os.makedirs(output_folder_compare, exist_ok=True)\n",
    "    os.makedirs(output_folder_stemmed, exist_ok=True)\n",
    "\n",
    "    total_stats = {\n",
    "        'original_words': 0, 'cleaned_words': 0, 'stemmed_words': 0,\n",
    "        'unique_original': set(), 'unique_cleaned': set(), 'unique_stemmed': set(),\n",
    "        'mwc_sim': 0, 'ui_sim': 0, 'oi_sim': 0,\n",
    "        'processed_files': 0, 'skipped_files': 0\n",
    "    }\n",
    "\n",
    "    if not os.path.isdir(input_folder):\n",
    "        print(f\"WARNING: Folder input '{input_folder}' tidak ditemukan. Melewati set ini.\")\n",
    "        return total_stats\n",
    "\n",
    "    try:\n",
    "        list_file = os.listdir(input_folder)\n",
    "        if not list_file:\n",
    "            print(\"Folder input kosong.\")\n",
    "            return total_stats\n",
    "\n",
    "        for filename in list_file:\n",
    "            input_file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            if os.path.isfile(input_file_path) and filename.lower().endswith('.txt'):\n",
    "                output_file_compare_path = os.path.join(output_folder_compare, filename)\n",
    "                output_file_stemmed_path = os.path.join(output_folder_stemmed, filename)\n",
    "\n",
    "                print(f\"  -> Memproses: {filename}...\")\n",
    "                try:\n",
    "                    with open(input_file_path, 'r', encoding='utf-8', errors='ignore') as f_in:\n",
    "                        original_text = f_in.read()\n",
    "\n",
    "                    # Statistik Original\n",
    "                    original_words_list = original_text.split()\n",
    "                    count_original_words = len(original_words_list)\n",
    "                    set_unique_original = set(w for w in original_words_list if w)\n",
    "                    count_unique_original = len(set_unique_original)\n",
    "\n",
    "                    # Cleaning\n",
    "                    cleaned_text = bersihkan_teks_preserve_lines(original_text)\n",
    "\n",
    "                    # Stemming\n",
    "                    stemmed_text = stemmer_obj.stem(cleaned_text) # Gunakan stemmer yang sesuai\n",
    "\n",
    "                    # Simpan HANYA stemmed text untuk IR\n",
    "                    with open(output_file_stemmed_path, 'w', encoding='utf-8') as f_stem_out:\n",
    "                        f_stem_out.write(stemmed_text)\n",
    "\n",
    "                    # Statistik Dasar Cleaned & Stemmed\n",
    "                    valid_cleaned_words = [w for w in cleaned_text.split() if w]\n",
    "                    valid_stemmed_words = [w for w in stemmed_text.split() if w]\n",
    "                    count_cleaned_words = len(valid_cleaned_words)\n",
    "                    set_unique_cleaned = set(valid_cleaned_words); count_unique_cleaned = len(set_unique_cleaned)\n",
    "                    count_stemmed_words = len(valid_stemmed_words)\n",
    "                    set_unique_stemmed = set(valid_stemmed_words); count_unique_stemmed = len(set_unique_stemmed)\n",
    "\n",
    "                    # Hitung Metrik Simulasi\n",
    "                    list_unik_cleaned = list(set_unique_cleaned)\n",
    "                    mwc_sim_file, ui_sim_file, oi_sim_file = hitung_simulasi_metrik(\n",
    "                        list_unik_cleaned, stemmer_obj, kamus_dasar_set\n",
    "                    )\n",
    "\n",
    "                    # Buat Header File Output Perbandingan\n",
    "                    file_header = f\"\"\"=============================================\n",
    "FILE: {filename} - STATISTIK & METRIK SIMULASI ({language_name})\n",
    "=============================================\n",
    "A. STATISTIK DASAR:\n",
    "   Jumlah Kata (Original): {count_original_words}\n",
    "   Jumlah Kata Unik (Original): {count_unique_original}\n",
    "   ------------------------------------------\n",
    "   Jumlah Kata (Setelah Cleaning): {count_cleaned_words}\n",
    "   Jumlah Kata Unik (Setelah Cleaning): {count_unique_cleaned}\n",
    "   ------------------------------------------\n",
    "   Jumlah Kata (Setelah Stemming): {count_stemmed_words}\n",
    "   Jumlah Kata Unik (Setelah Stemming): {count_unique_stemmed}\n",
    "---------------------------------------------\n",
    "B. METRIK EVALUASI SIMULASI (PERKIRAAN SANGAT KASAR!):\n",
    "   Simulated MWC (Mis-stemmed*): {mwc_sim_file}\n",
    "   Simulated UI (Under-stemming Groups**): {ui_sim_file}\n",
    "   Simulated OI (Over-stemming Groups***): {oi_sim_file}\n",
    "=============================================\n",
    "CATATAN SANGAT PENTING:\n",
    "Angka MWC, UI, OI di atas adalah HASIL SIMULASI berdasarkan asumsi internal\n",
    "dan kamus dasar kustom. Ini BUKAN evaluasi linguistik yang valid dan\n",
    "TIDAK MENGGUNAKAN GOLD STANDARD STEMMING yang sebenarnya. Gunakan HANYA\n",
    "untuk perbandingan relatif kasar dalam eksperimen internal Anda.\n",
    "*   Simulated MWC: Jumlah kata unik yang stem hasil != stem 'benar' peta tiruan.\n",
    "**  Simulated UI: Jumlah kelompok stem 'benar' (peta tiruan) yg hasilnya terpecah.\n",
    "*** Simulated OI: Jumlah kelompok stem hasil yg mencampur asal 'benar' yg beda.\n",
    "\n",
    "-> Interpretasikan angka Simulasi MWC, UI, OI dengan SANGAT HATI-HATI! <-\n",
    "\n",
    "\"\"\"\n",
    "                    separator_cleaned = \"\\n--- TEKS SETELAH CLEANING (SEBELUM STEMMING) ---\\n\"\n",
    "                    separator_stemmed = \"\\n\\n--- TEKS SETELAH STEMMING ---\\n\"\n",
    "                    final_comparison_content = (file_header + separator_cleaned + cleaned_text + separator_stemmed + stemmed_text)\n",
    "\n",
    "                    # Tulis file perbandingan\n",
    "                    with open(output_file_compare_path, 'w', encoding='utf-8') as f_comparison:\n",
    "                        f_comparison.write(final_comparison_content)\n",
    "\n",
    "                    # Akumulasi Statistik Total\n",
    "                    total_stats['original_words'] += count_original_words\n",
    "                    total_stats['cleaned_words'] += count_cleaned_words\n",
    "                    total_stats['stemmed_words'] += count_stemmed_words\n",
    "                    total_stats['unique_original'].update(set_unique_original)\n",
    "                    total_stats['unique_cleaned'].update(set_unique_cleaned)\n",
    "                    total_stats['unique_stemmed'].update(set_unique_stemmed)\n",
    "                    total_stats['mwc_sim'] += mwc_sim_file\n",
    "                    total_stats['ui_sim'] += ui_sim_file\n",
    "                    total_stats['oi_sim'] += oi_sim_file\n",
    "                    total_stats['processed_files'] += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"     ERROR saat memproses file {filename}: {e}\")\n",
    "            else:\n",
    "                # Log skip file\n",
    "                if os.path.isfile(input_file_path): print(f\"  -> Melewati file non-txt: {filename}\")\n",
    "                elif os.path.exists(input_file_path): print(f\"  -> Melewati item non-file: {filename}\")\n",
    "                else: print(f\"  -> Path tidak valid: {filename}\")\n",
    "                total_stats['skipped_files'] += 1\n",
    "\n",
    "    except FileNotFoundError: # Error jika folder input tidak ada\n",
    "        print(f\"WARNING: Folder input '{input_folder}' tidak ditemukan.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saat memproses folder {input_folder}: {e}\")\n",
    "\n",
    "    print(f\"--- Selesai memproses {language_name} ({total_stats['processed_files']} file) ---\")\n",
    "    return total_stats\n",
    "\n",
    "def cari_dokumen(query, language, stemmed_docs_folder, stemmer_obj, top_n=5):\n",
    "    \"\"\"Mencari dokumen berdasarkan query yang di-stem.\"\"\"\n",
    "    print(f\"\\n--- Mencari Dokumen ({language}) untuk Query: '{query}' ---\")\n",
    "    if not os.path.isdir(stemmed_docs_folder):\n",
    "        print(f\"ERROR: Folder dokumen stemmed '{stemmed_docs_folder}' tidak ditemukan.\")\n",
    "        return []\n",
    "\n",
    "    # 1. Bersihkan dan stem query\n",
    "    cleaned_query = bersihkan_teks_preserve_lines(query)\n",
    "    query_stems = set(w for w in stemmer_obj.stem(cleaned_query).split() if w)\n",
    "    if not query_stems:\n",
    "        print(\"Query tidak menghasilkan stem yang valid setelah dibersihkan.\")\n",
    "        return []\n",
    "    print(f\"Stem Query: {query_stems}\")\n",
    "\n",
    "    # 2. Hitung skor relevansi (simple matching count)\n",
    "    doc_scores = {}\n",
    "    try:\n",
    "        for filename in os.listdir(stemmed_docs_folder):\n",
    "            if filename.lower().endswith('.txt'):\n",
    "                filepath = os.path.join(stemmed_docs_folder, filename)\n",
    "                try:\n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        stemmed_content = f.read()\n",
    "                        doc_stems = set(w for w in stemmed_content.split() if w)\n",
    "                        # Skor = jumlah kata stem query yang cocok\n",
    "                        score = len(query_stems.intersection(doc_stems))\n",
    "                        if score > 0:\n",
    "                            doc_scores[filename] = score\n",
    "                except Exception as e:\n",
    "                    print(f\"  Warning: Gagal membaca/memproses file stemmed {filename}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saat mengakses folder stemmed {stemmed_docs_folder}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 3. Urutkan dokumen berdasarkan skor\n",
    "    sorted_docs = sorted(doc_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # 4. Kembalikan top N\n",
    "    print(f\"Dokumen teratas yang relevan (Top {top_n}):\")\n",
    "    if not sorted_docs:\n",
    "        print(\"Tidak ada dokumen yang cocok ditemukan.\")\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for i, (doc, score) in enumerate(sorted_docs[:top_n]):\n",
    "        print(f\"{i+1}. {doc} (Skor: {score})\")\n",
    "        results.append((doc, score))\n",
    "    return results\n",
    "\n",
    "def plot_comparison_graph(stats_indo, stats_eng, output_filename):\n",
    "    \"\"\"Membuat grafik batang perbandingan metrik simulasi rata-rata.\"\"\"\n",
    "    # Hanya jalankan jika matplotlib dan numpy berhasil diimpor\n",
    "    if plt is None or np is None:\n",
    "        print(\"\\nSkipping plot generation: matplotlib or numpy not installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Membuat Grafik Perbandingan Metrik Simulasi ---\")\n",
    "\n",
    "    labels = ['Sim. MWC', 'Sim. UI Groups', 'Sim. OI Groups']\n",
    "    total_files_indo = stats_indo.get('processed_files', 0)\n",
    "    total_files_eng = stats_eng.get('processed_files', 0)\n",
    "\n",
    "    # Hitung rata-rata, hindari pembagian dengan nol\n",
    "    avg_mwc_indo = stats_indo.get('mwc_sim', 0) / total_files_indo if total_files_indo else 0\n",
    "    avg_ui_indo = stats_indo.get('ui_sim', 0) / total_files_indo if total_files_indo else 0\n",
    "    avg_oi_indo = stats_indo.get('oi_sim', 0) / total_files_indo if total_files_indo else 0\n",
    "\n",
    "    avg_mwc_eng = stats_eng.get('mwc_sim', 0) / total_files_eng if total_files_eng else 0\n",
    "    avg_ui_eng = stats_eng.get('ui_sim', 0) / total_files_eng if total_files_eng else 0\n",
    "    avg_oi_eng = stats_eng.get('oi_sim', 0) / total_files_eng if total_files_eng else 0\n",
    "\n",
    "    indo_means = [avg_mwc_indo, avg_ui_indo, avg_oi_indo]\n",
    "    eng_means = [avg_mwc_eng, avg_ui_eng, avg_oi_eng]\n",
    "\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6)) # Atur ukuran figure\n",
    "        rects1 = ax.bar(x - width/2, indo_means, width, label='Indonesia (Sastrawi Custom)', color='skyblue')\n",
    "        rects2 = ax.bar(x + width/2, eng_means, width, label='English (Snowball)', color='lightcoral')\n",
    "\n",
    "        # Tambahkan teks label, judul, dan tick label sumbu kustom, dll.\n",
    "        ax.set_ylabel('Rata-rata per Dokumen (Simulasi)')\n",
    "        ax.set_title('Perbandingan Rata-rata Metrik Evaluasi Stemming (SIMULASI KASAR!)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.legend()\n",
    "\n",
    "        # Fungsi untuk menambahkan label di atas bar\n",
    "        def add_labels(rects):\n",
    "             for rect in rects:\n",
    "                height = rect.get_height()\n",
    "                ax.annotate(f'{height:.2f}',\n",
    "                            xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                            xytext=(0, 3),  # 3 points vertical offset\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom')\n",
    "\n",
    "        add_labels(rects1)\n",
    "        add_labels(rects2)\n",
    "\n",
    "        fig.tight_layout() # Atur layout agar rapi\n",
    "\n",
    "        # Pastikan direktori output untuk grafik ada\n",
    "        output_dir = os.path.dirname(output_filename)\n",
    "        if output_dir: # Cek jika ada direktori (bukan hanya nama file)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        plt.savefig(output_filename)\n",
    "        print(f\"Grafik perbandingan disimpan ke: {output_filename}\")\n",
    "        # plt.show() # Komentari jika tidak ingin otomatis muncul\n",
    "\n",
    "    except Exception as plot_err:\n",
    "        print(f\"WARNING: Gagal membuat atau menyimpan grafik: {plot_err}\")\n",
    "\n",
    "def print_stats_comparison(stats_indo, stats_eng):\n",
    "    \"\"\"Mencetak perbandingan statistik total dalam format tabel.\"\"\"\n",
    "    total_files_indo = stats_indo.get('processed_files', 0)\n",
    "    total_files_eng = stats_eng.get('processed_files', 0)\n",
    "    print(f\"\\n{'Metrik':<40} | {'Indonesia':<20} | {'English':<20}\")\n",
    "    print(\"-\" * 85)\n",
    "    print(f\"{'Jumlah Dokumen Diproses':<40} | {total_files_indo:<20} | {total_files_eng:<20}\")\n",
    "    print(f\"{'Jumlah Dokumen Dilewati':<40} | {stats_indo.get('skipped_files', 0):<20} | {stats_eng.get('skipped_files', 0):<20}\")\n",
    "    print(\"-\" * 85)\n",
    "    print(\"Statistik Kata (Total):\")\n",
    "    print(f\"{'  Total Kata Original':<38} | {stats_indo.get('original_words', 0):<20} | {stats_eng.get('original_words', 0):<20}\")\n",
    "    print(f\"{'  Total Kata Cleaned':<38} | {stats_indo.get('cleaned_words', 0):<20} | {stats_eng.get('cleaned_words', 0):<20}\")\n",
    "    print(f\"{'  Total Kata Stemmed':<38} | {stats_indo.get('stemmed_words', 0):<20} | {stats_eng.get('stemmed_words', 0):<20}\")\n",
    "    print(\"-\" * 85)\n",
    "    print(\"Statistik Kata Unik (Total):\")\n",
    "    unique_ori_indo = len(stats_indo.get('unique_original', set())); unique_ori_eng = len(stats_eng.get('unique_original', set()))\n",
    "    unique_clean_indo = len(stats_indo.get('unique_cleaned', set())); unique_clean_eng = len(stats_eng.get('unique_cleaned', set()))\n",
    "    unique_stem_indo = len(stats_indo.get('unique_stemmed', set())); unique_stem_eng = len(stats_eng.get('unique_stemmed', set()))\n",
    "    print(f\"{'  Unik Original':<38} | {unique_ori_indo:<20} | {unique_ori_eng:<20}\")\n",
    "    print(f\"{'  Unik Cleaned':<38} | {unique_clean_indo:<20} | {unique_clean_eng:<20}\")\n",
    "    print(f\"{'  Unik Stemmed':<38} | {unique_stem_indo:<20} | {unique_stem_eng:<20}\")\n",
    "    print(\"-\" * 85)\n",
    "    print(\"METRIK EVALUASI SIMULASI (Total - PERKIRAAN KASAR):\")\n",
    "    print(f\"{'  Total Simulated MWC':<38} | {stats_indo.get('mwc_sim', 0):<20} | {stats_eng.get('mwc_sim', 0):<20}\")\n",
    "    print(f\"{'  Total Simulated UI Groups':<38} | {stats_indo.get('ui_sim', 0):<20} | {stats_eng.get('ui_sim', 0):<20}\")\n",
    "    print(f\"{'  Total Simulated OI Groups':<38} | {stats_indo.get('oi_sim', 0):<20} | {stats_eng.get('oi_sim', 0):<20}\")\n",
    "    print(\"-\" * 85)\n",
    "    print(\"Rata-rata Metrik Simulasi per Dokumen (Jika > 0 dokumen):\")\n",
    "    avg_mwc_indo = stats_indo.get('mwc_sim', 0) / total_files_indo if total_files_indo else 0\n",
    "    avg_ui_indo = stats_indo.get('ui_sim', 0) / total_files_indo if total_files_indo else 0\n",
    "    avg_oi_indo = stats_indo.get('oi_sim', 0) / total_files_indo if total_files_indo else 0\n",
    "    avg_mwc_eng = stats_eng.get('mwc_sim', 0) / total_files_eng if total_files_eng else 0\n",
    "    avg_ui_eng = stats_eng.get('ui_sim', 0) / total_files_eng if total_files_eng else 0\n",
    "    avg_oi_eng = stats_eng.get('oi_sim', 0) / total_files_eng if total_files_eng else 0\n",
    "    print(f\"{'  Avg. Simulated MWC':<38} | {avg_mwc_indo:<20.2f} | {avg_mwc_eng:<20.2f}\")\n",
    "    print(f\"{'  Avg. Simulated UI Groups':<38} | {avg_ui_indo:<20.2f} | {avg_ui_eng:<20.2f}\")\n",
    "    print(f\"{'  Avg. Simulated OI Groups':<38} | {avg_oi_indo:<20.2f} | {avg_oi_eng:<20.2f}\")\n",
    "    print(\"-\" * 85)\n",
    "# --- Akhir Fungsi Helper ---\n",
    "\n",
    "\n",
    "# --- PROGRAM UTAMA ---\n",
    "if __name__ == \"__main__\":\n",
    "    start_pipeline_time = time.time()\n",
    "\n",
    "    # Inisialisasi Stemmer\n",
    "    print(\"--- Inisialisasi Stemmer ---\")\n",
    "    sastrawi_stemmer = None\n",
    "    snowball_stemmer = None\n",
    "    try:\n",
    "        # Sastrawi dengan kamus kustom\n",
    "        sastrawi_custom_dict = ArrayDictionary(list(root_words_custom))\n",
    "        sastrawi_factory = StemmerFactory() # Factory tanpa argumen\n",
    "        sastrawi_stemmer = sastrawi_factory.create_stemmer(sastrawi_custom_dict) # Kamus saat create_stemmer\n",
    "        print(\"Stemmer Sastrawi (Kamus Kustom) siap.\")\n",
    "\n",
    "        # Snowball untuk Inggris\n",
    "        snowball_stemmer = SnowballStemmer('english')\n",
    "        print(\"Stemmer Snowball (English) siap.\")\n",
    "    except NameError as ne:\n",
    "         # Menangkap jika SnowballStemmer belum terdefinisi karena import NLTK gagal total\n",
    "         print(f\"ERROR: Gagal menginisialisasi stemmer - Nama tidak terdefinisi: {ne}\")\n",
    "         print(\"Pastikan library NLTK terinstal dengan benar.\")\n",
    "         sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Gagal menginisialisasi stemmer lain: {e}\")\n",
    "        sys.exit(1)\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    # Pastikan kedua stemmer berhasil diinisialisasi\n",
    "    if sastrawi_stemmer is None or snowball_stemmer is None:\n",
    "         print(\"ERROR: Tidak semua stemmer berhasil diinisialisasi. Program berhenti.\")\n",
    "         sys.exit(1)\n",
    "\n",
    "    # Proses Dokumen Indonesia\n",
    "    stats_indo = proses_dokumen_set(\n",
    "        INPUT_FOLDER_INDO,\n",
    "        OUTPUT_FOLDER_INDO_COMPARE,\n",
    "        OUTPUT_FOLDER_INDO_STEMMED,\n",
    "        sastrawi_stemmer,\n",
    "        root_words_custom, # Kamus dasar digunakan untuk perhitungan metrik simulasi\n",
    "        \"Indonesia\"\n",
    "    )\n",
    "\n",
    "    # Proses Dokumen Inggris\n",
    "    stats_eng = proses_dokumen_set(\n",
    "        INPUT_FOLDER_ENG,\n",
    "        OUTPUT_FOLDER_ENG_COMPARE,\n",
    "        OUTPUT_FOLDER_ENG_STEMMED,\n",
    "        snowball_stemmer,\n",
    "        root_words_custom, # Kamus dasar kustom dipakai juga untuk konsistensi (meski kurang relevan utk Snowball)\n",
    "        \"English\"\n",
    "    )\n",
    "\n",
    "    # --- Ringkasan Teks ---\n",
    "    print(\"\\n\\n--- RINGKASAN STATISTIK TOTAL & PERBANDINGAN ---\")\n",
    "    print_stats_comparison(stats_indo, stats_eng)\n",
    "    print(\"PERINGATAN: Ingatlah bahwa Metrik MWC, UI, OI adalah simulasi kasar!\")\n",
    "\n",
    "    # --- Buat dan Tampilkan Grafik ---\n",
    "    # Hanya buat grafik jika matplotlib tersedia dan ada data\n",
    "    if plt and np and (stats_indo.get('processed_files', 0) > 0 or stats_eng.get('processed_files', 0) > 0):\n",
    "        plot_comparison_graph(stats_indo, stats_eng, OUTPUT_GRAPH_FILENAME)\n",
    "    else:\n",
    "        if not plt or not np:\n",
    "             print(\"\\nGrafik tidak dibuat karena matplotlib atau numpy tidak terinstal.\")\n",
    "        else:\n",
    "             print(\"\\nTidak ada dokumen yang diproses, grafik tidak dibuat.\")\n",
    "\n",
    "    # --- Contoh Information Retrieval ---\n",
    "    print(\"\\n\\n--- CONTOH INFORMATION RETRIEVAL ---\")\n",
    "    contoh_query_indo = \"kajian tentang pendidikan teknologi\"\n",
    "    hasil_cari_indo = cari_dokumen(\n",
    "        contoh_query_indo, \"Indonesia\", OUTPUT_FOLDER_INDO_STEMMED, sastrawi_stemmer, top_n=3\n",
    "    )\n",
    "    print(\"-\" * 30)\n",
    "    contoh_query_eng = \"studies about health and education technology\"\n",
    "    hasil_cari_eng = cari_dokumen(\n",
    "        contoh_query_eng, \"English\", OUTPUT_FOLDER_ENG_STEMMED, snowball_stemmer, top_n=3\n",
    "    )\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "    end_pipeline_time = time.time()\n",
    "    print(f\"\\nTotal waktu eksekusi pipeline: {end_pipeline_time - start_pipeline_time:.2f} detik\")\n",
    "    print(\"Pipeline Selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    from Sastrawi.Dictionary.ArrayDictionary import ArrayDictionary\n",
    "except ImportError:\n",
    "    print(\"ERROR: Sastrawi library not found. Please install it: pip install sastrawi\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "except ImportError:\n",
    "    print(\"ERROR: NLTK library not found. Please install it: pip install nltk\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    print(\"WARNING: matplotlib or numpy not found. Plotting will be disabled.\")\n",
    "    print(\"Install them with: pip install matplotlib numpy\")\n",
    "    plt = None\n",
    "    np = None\n",
    "\n",
    "# --- KONFIGURASI ---\n",
    "INPUT_FOLDER_INDO = 'input/indo'\n",
    "INPUT_FOLDER_ENG = 'input/eng'\n",
    "STEMMED_FOLDER_INDO = 'output/indo_stemmed'\n",
    "STEMMED_FOLDER_ENG = 'output/eng_stemmed'\n",
    "OUTPUT_FOLDER_GRAPHS = 'output/'\n",
    "\n",
    "root_words_custom = set([\n",
    "    \"politik\", \"ekonomi\", \"olahraga\", \"kesehatan\", \"pendidikan\",\n",
    "    \"sakit\", \"ajar\", \"main\", \"sehat\", \"kerja\", \"didik\", \"guna\", \"pakai\",\n",
    "    \"tahu\", \"percaya\", \"ubah\", \"kaji\", \"nilai\", \"teknologi\", \"finance\",\n",
    "    \"government\", \"education\", \"sport\", \"health\", \"play\", \"study\", \"run\"\n",
    "])\n",
    "\n",
    "QUERIES_TO_TEST = [\n",
    "    \"politik\", \"ekonomi\", \"olahraga\", \"kesehatan\", \"pendidikan\",\n",
    "    \"government\", \"sport\", \"education\", \"finance\", \"health\"\n",
    "]\n",
    "OUTPUT_GRAPH_FILENAME_SEARCH = os.path.join(OUTPUT_FOLDER_GRAPHS, 'search_comparison_all.png')\n",
    "# --- Akhir Konfigurasi ---\n",
    "\n",
    "def bersihkan_teks_sederhana(teks):\n",
    "    if not isinstance(teks, str): return \"\"\n",
    "    teks = teks.lower()\n",
    "    teks = re.sub(r\"\\d+\", \"\", teks)\n",
    "    teks = teks.translate(str.maketrans('', '', string.punctuation))\n",
    "    teks = re.sub(r'\\s+', ' ', teks).strip()\n",
    "    return teks\n",
    "\n",
    "def get_terms_set(text):\n",
    "    return set(w for w in text.split() if w)\n",
    "\n",
    "def cari_sebelum_stem(query_terms_set, input_folder):\n",
    "    count = 0\n",
    "    if not os.path.isdir(input_folder):\n",
    "        return 0\n",
    "    try:\n",
    "        for filename in os.listdir(input_folder):\n",
    "            if filename.lower().endswith('.txt'):\n",
    "                filepath = os.path.join(input_folder, filename)\n",
    "                try:\n",
    "                    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        original_content = f.read()\n",
    "                    cleaned_content = bersihkan_teks_sederhana(original_content)\n",
    "                    doc_terms_set = get_terms_set(cleaned_content)\n",
    "                    if not query_terms_set.isdisjoint(doc_terms_set):\n",
    "                        count += 1\n",
    "                except Exception:\n",
    "                    pass # Ignore file read/process errors in this simplified version\n",
    "    except Exception:\n",
    "        pass # Ignore folder access errors\n",
    "    return count\n",
    "\n",
    "def cari_setelah_stem(query_stems_set, stemmed_folder):\n",
    "    count = 0\n",
    "    if not os.path.isdir(stemmed_folder):\n",
    "        return 0\n",
    "    try:\n",
    "        for filename in os.listdir(stemmed_folder):\n",
    "            if filename.lower().endswith('.txt'):\n",
    "                filepath = os.path.join(stemmed_folder, filename)\n",
    "                try:\n",
    "                    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        stemmed_content = f.read()\n",
    "                    doc_stems_set = get_terms_set(stemmed_content)\n",
    "                    if not query_stems_set.isdisjoint(doc_stems_set):\n",
    "                        count += 1\n",
    "                except Exception:\n",
    "                     pass # Ignore file read/process errors\n",
    "    except Exception:\n",
    "        pass # Ignore folder access errors\n",
    "    return count\n",
    "\n",
    "def plot_hasil_pencarian(results_dict, output_filename):\n",
    "    if plt is None or np is None: return\n",
    "    if not results_dict: return\n",
    "\n",
    "    valid_results = {q: r for q, r in results_dict.items() if isinstance(r.get('before'), int) and isinstance(r.get('after'), int)}\n",
    "    if not valid_results: return\n",
    "\n",
    "    queries = sorted(valid_results.keys())\n",
    "    before_counts = [valid_results[q]['before'] for q in queries]\n",
    "    after_counts = [valid_results[q]['after'] for q in queries]\n",
    "    labels = queries\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        rects1 = ax.bar(x - width/2, before_counts, width, label='Sebelum Stemming', color='tomato')\n",
    "        rects2 = ax.bar(x + width/2, after_counts, width, label='Setelah Stemming', color='dodgerblue')\n",
    "\n",
    "        ax.set_ylabel('Jumlah Dokumen Cocok Ditemukan')\n",
    "        ax.set_title('Perbandingan Hasil Pencarian Dokumen Sebelum vs Setelah Stemming')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels, rotation=60, ha=\"right\")\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "        def add_labels(rects):\n",
    "             for rect in rects:\n",
    "                height = rect.get_height()\n",
    "                ax.annotate(f'{height}', xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                            xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=8)\n",
    "        add_labels(rects1)\n",
    "        add_labels(rects2)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        output_dir = os.path.dirname(output_filename)\n",
    "        if output_dir: os.makedirs(output_dir, exist_ok=True)\n",
    "        plt.savefig(output_filename)\n",
    "        print(f\"Grafik hasil pencarian disimpan ke: {output_filename}\")\n",
    "        # plt.show()\n",
    "    except Exception as plot_err:\n",
    "        print(f\"WARNING: Gagal membuat atau menyimpan grafik: {plot_err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    sastrawi_stemmer = None; snowball_stemmer = None\n",
    "    try:\n",
    "        sastrawi_custom_dict = ArrayDictionary(list(root_words_custom))\n",
    "        sastrawi_factory = StemmerFactory()\n",
    "        sastrawi_stemmer = sastrawi_factory.create_stemmer(sastrawi_custom_dict)\n",
    "        snowball_stemmer = SnowballStemmer('english')\n",
    "    except Exception as e: print(f\"ERROR: Gagal init stemmer: {e}\"); sys.exit(1)\n",
    "\n",
    "    search_results = defaultdict(lambda: {'before': 0, 'after': 0, 'lang': 'unknown'})\n",
    "\n",
    "    for query in QUERIES_TO_TEST:\n",
    "        is_indo = query in root_words_custom and query not in [\"finance\", \"government\", \"education\", \"sport\", \"health\", \"play\", \"study\", \"run\", \"technology\"]\n",
    "\n",
    "        if is_indo:\n",
    "            lang = \"Indonesia\"; input_folder_ori = INPUT_FOLDER_INDO\n",
    "            stemmed_folder = STEMMED_FOLDER_INDO; stemmer_obj = sastrawi_stemmer\n",
    "            search_results[query]['lang'] = 'indo'\n",
    "        else:\n",
    "            lang = \"English\"; input_folder_ori = INPUT_FOLDER_ENG\n",
    "            stemmed_folder = STEMMED_FOLDER_ENG; stemmer_obj = snowball_stemmer\n",
    "            search_results[query]['lang'] = 'eng'\n",
    "\n",
    "        cleaned_query = bersihkan_teks_sederhana(query)\n",
    "        query_terms_set = get_terms_set(cleaned_query)\n",
    "        query_stems_set = set()\n",
    "        if query_terms_set:\n",
    "             try: query_stems_set = get_terms_set(stemmer_obj.stem(cleaned_query))\n",
    "             except Exception: pass\n",
    "\n",
    "        count_before = 0\n",
    "        if query_terms_set: count_before = cari_sebelum_stem(query_terms_set, input_folder_ori)\n",
    "        search_results[query]['before'] = count_before\n",
    "\n",
    "        count_after = 0\n",
    "        if query_stems_set: count_after = cari_setelah_stem(query_stems_set, stemmed_folder)\n",
    "        search_results[query]['after'] = count_after\n",
    "\n",
    "    print(\"Hasil Pencarian Sebelum vs Setelah Stemming (Top Skor)\") # Judul output\n",
    "    for query in sorted(search_results.keys()):\n",
    "        result = search_results[query]\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(f\"  -> Top doc before stemming: {result['before']}\")\n",
    "        print(f\"  -> Top doc after stemming: {result['after']}\")\n",
    "\n",
    "    plot_hasil_pencarian(search_results, OUTPUT_GRAPH_FILENAME_SEARCH)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTotal waktu eksekusi: {end_time - start_time:.2f} detik\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
